"""
PIPELINE T·ª∞ ƒê·ªòNG H√ìA PH√ÅT HI·ªÜN SUY GI·∫¢M KPI
============================================
Workflow:
1. ƒê·ªçc d·ªØ li·ªáu CSV v√† t·∫°o pivot chart line (trend analysis)
2. Ph√°t hi·ªán KPI n√†o c·ªßa t·ªânh n√†o ƒëang suy gi·∫£m m·∫°nh
3. T·ª± ƒë·ªông t·∫£i d·ªØ li·ªáu c·∫•p huy·ªán khi ph√°t hi·ªán v·∫•n ƒë·ªÅ
4. T·∫°o b√°o c√°o v√† alert
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# Optional imports
try:
    import seaborn as sns
    HAS_SEABORN = True
except ImportError:
    HAS_SEABORN = False
    print("‚ö†Ô∏è  seaborn kh√¥ng ƒë∆∞·ª£c c√†i ƒë·∫∑t. M·ªôt s·ªë t√≠nh nƒÉng visualization c√≥ th·ªÉ b·ªã h·∫°n ch·∫ø.")

# Import c√°c module h·ªó tr·ª£
try:
    from visualization_module import KPIVisualization
    from alert_system import AlertSystem
except ImportError:
    print("‚ö†Ô∏è  C√°c module h·ªó tr·ª£ ch∆∞a ƒë∆∞·ª£c import. Ch·∫°y file n√†y trong c√πng th∆∞ m·ª•c.")
    KPIVisualization = None
    AlertSystem = None

# C·∫•u h√¨nh
CONFIG = {
    'decline_threshold': 2.0,  # % suy gi·∫£m ƒë·ªÉ trigger alert
    'days_lookback': 7,  # S·ªë ng√†y ƒë·ªÉ so s√°nh trend
    'critical_kpis': ['MTCL_2024', 'CSSR', 'CDR', 'ERAB_SR_2022', 'HOSR_4G_2024'],  # KPI quan tr·ªçng
    'output_dir': 'reports',
    'charts_dir': 'charts',
    # Quy t·∫Øc theo KPI: h∆∞·ªõng t·ªët/x·∫•u v√† ng∆∞·ª°ng m·ª•c ti√™u
    # v√≠ d·ª• theo file PDF: CDR <= 0.35% (t·ª©c l√† gi√° tr·ªã nh·ªè h∆°n th√¨ t·ªët)
    'kpi_rules': {
        'CDR': { 'direction': 'lower_better', 'limit': 0.35 },
        # V√≠ d·ª• th√™m: 'CSSR': { 'direction': 'higher_better', 'limit': 99.0 }
    }
}


class KPIDeclineDetector:
    """Class ch√≠nh ƒë·ªÉ ph√°t hi·ªán suy gi·∫£m KPI"""
    
    def __init__(self, file_path: str, config: Dict = None):
        self.file_path = file_path
        self.config = config or CONFIG
        self.df = None
        self.province_trends = {}
        self.decline_alerts = []
        
    def _get_kpi_rule(self, kpi_column: str) -> Optional[Dict]:
        """T√¨m rule theo t√™n KPI (match ti·ªÅn t·ªë, kh√¥ng ph√¢n bi·ªát hoa/th∆∞·ªùng)."""
        rules = self.config.get('kpi_rules') or {}
        kpi_up = str(kpi_column).upper()
        for key, rule in rules.items():
            if key.upper() in kpi_up:
                return rule
        return None

    def _is_worsening(self, latest: float, compare: float, rule: Optional[Dict]) -> Tuple[bool, float]:
        """X√°c ƒë·ªãnh c√≥ xu h∆∞·ªõng x·∫•u ƒëi theo h∆∞·ªõng KPI.
        Tr·∫£ v·ªÅ (is_worse, change_pct_directionsigned)
        """
        if compare is None or compare == 0:
            return False, 0.0
        change_pct = ((latest - compare) / compare) * 100.0
        if rule and rule.get('direction') == 'lower_better':
            # TƒÉng l√† x·∫•u
            return change_pct > 0, change_pct
        # M·∫∑c ƒë·ªãnh: higher_better ‚Üí gi·∫£m l√† x·∫•u
        return change_pct < 0, change_pct

    def _is_limit_breached(self, value: float, rule: Optional[Dict]) -> Optional[bool]:
        """Ki·ªÉm tra c√≥ vi ph·∫°m ng∆∞·ª°ng hay kh√¥ng. None n·∫øu kh√¥ng c√≥ rule/limit."""
        if not rule or 'limit' not in rule:
            return None
        limit = rule['limit']
        direction = rule.get('direction', 'higher_better')
        if direction == 'lower_better':
            return value > limit
        return value < limit

    def load_and_clean_data(self):
        """ƒê·ªçc v√† l√†m s·∫°ch d·ªØ li·ªáu"""
        print("üìñ ƒêang ƒë·ªçc d·ªØ li·ªáu...")
        
        # ƒê·ªçc CSV
        self.df = pd.read_csv(self.file_path, encoding='utf-8')
        
        # Parse ng√†y
        self.df['Ngay7'] = pd.to_datetime(self.df['Ngay7'], format='%d/%m/%Y', errors='coerce')
        
        # L√†m s·∫°ch c√°c c·ªôt s·ªë
        numeric_cols = self._get_numeric_columns()
        for col in numeric_cols:
            if col in self.df.columns:
                self.df[col] = self._clean_numeric_column(self.df[col])
        
        # L·ªçc b·ªè d√≤ng kh√¥ng c√≥ t·ªânh
        self.df = self.df[self.df['CTKD7'].notna()].copy()
        
        print(f"‚úÖ ƒê√£ load {len(self.df)} d√≤ng d·ªØ li·ªáu")
        print(f"   - T·ª´ {self.df['Ngay7'].min().date()} ƒë·∫øn {self.df['Ngay7'].max().date()}")
        print(f"   - S·ªë t·ªânh: {self.df['CTKD7'].nunique()}")
        
        return self.df
    
    def _get_numeric_columns(self) -> List[str]:
        """L·∫•y danh s√°ch c√°c c·ªôt s·ªë"""
        return [
            'MTCL_2024', 'MTCL_2024_Giamtru',
            'HTMT_QoS', 'DiemHTMT_KPI', 'DiemHTMT_KPI_Giamtru',
            'CSSR', 'CSSR_Giamtru', 'CDR', 'CDR_GiamTru',
            'ERAB_SR_2022', 'ERAB_SR_2022_GIAMTRU',
            'ERAB_DR_2022', 'ERAB_DR_2022_GIAMTRU',
            'HOSR_4G_2024', 'VN_CSSR', 'VN_CALL_DR',
            'ID4G_USR_DL_THP', 'ChatLuongVungPhu'
        ]
    
    def _clean_numeric_column(self, series: pd.Series) -> pd.Series:
        """L√†m s·∫°ch c·ªôt s·ªë: x·ª≠ l√Ω d·∫•u ph·∫©y, d·∫•u ngo·∫∑c k√©p"""
        series = series.astype(str)
        series = series.str.replace('"', '', regex=False)
        series = series.str.replace(',', '', regex=False)
        return pd.to_numeric(series, errors='coerce')
    
    def calculate_trends(self, kpi_column: str, province: str = None) -> pd.DataFrame:
        """
        T√≠nh to√°n trend (xu h∆∞·ªõng) cho KPI
        
        Args:
            kpi_column: T√™n c·ªôt KPI c·∫ßn ph√¢n t√≠ch
            province: T√™n t·ªânh (None = t·∫•t c·∫£ t·ªânh)
        
        Returns:
            DataFrame v·ªõi trend analysis
        """
        # L·ªçc d·ªØ li·ªáu (b·ªè qua gi√° tr·ªã 0 v√† null)
        df_filtered = self.df.copy()
        if province:
            df_filtered = df_filtered[df_filtered['CTKD7'] == province]
        
        # QUAN TR·ªåNG: B·ªè qua c√°c ng√†y c√≥ KPI = 0 ho·∫∑c null (kh√¥ng t√≠nh to√°n trend)
        df_filtered = df_filtered[
            (df_filtered[kpi_column].notna()) & 
            (df_filtered[kpi_column] != 0)
        ].copy()
        
        # Nh√≥m theo ng√†y v√† t·ªânh
        if province:
            daily_avg = df_filtered.groupby('Ngay7')[kpi_column].mean().reset_index()
            daily_avg['CTKD7'] = province
        else:
            daily_avg = df_filtered.groupby(['Ngay7', 'CTKD7'])[kpi_column].mean().reset_index()
        
        # T√≠nh to√°n c√°c metrics
        daily_avg = daily_avg.sort_values('Ngay7')
        
        # Rate of change (t·ª∑ l·ªá thay ƒë·ªïi)
        daily_avg['change_pct'] = daily_avg.groupby('CTKD7')[kpi_column].pct_change() * 100
        
        # Moving average (trung b√¨nh ƒë·ªông)
        daily_avg['ma_7d'] = daily_avg.groupby('CTKD7')[kpi_column].transform(
            lambda x: x.rolling(window=7, min_periods=1).mean()
        )
        
        # Trend direction (xu h∆∞·ªõng: tƒÉng/gi·∫£m/·ªïn ƒë·ªãnh)
        daily_avg['trend'] = daily_avg.groupby('CTKD7')['change_pct'].transform(
            lambda x: np.where(x > 0.5, 'TƒÉng', np.where(x < -0.5, 'Gi·∫£m', '·ªîn ƒë·ªãnh'))
        )
        
        return daily_avg
    
    def detect_declines(self, kpi_column: str, lookback_days: int = None) -> List[Dict]:
        """
        Ph√°t hi·ªán c√°c t·ªânh c√≥ KPI suy gi·∫£m m·∫°nh
        
        Args:
            kpi_column: T√™n c·ªôt KPI
            lookback_days: S·ªë ng√†y ƒë·ªÉ so s√°nh (default: t·ª´ config)
        
        Returns:
            List c√°c alert dict
        """
        lookback_days = lookback_days or self.config['days_lookback']
        threshold = self.config['decline_threshold']
        kpi_rule = self._get_kpi_rule(kpi_column)
        
        print(f"\nüîç ƒêang ph√¢n t√≠ch suy gi·∫£m cho {kpi_column}...")
        
        alerts = []
        provinces = self.df['CTKD7'].unique()
        
        for province in provinces:
            # QUAN TR·ªåNG: L·∫•y d·ªØ li·ªáu c·ªßa t·ªânh, b·ªè qua c√°c ng√†y c√≥ KPI = 0 ho·∫∑c null
            province_data = self.df[
                (self.df['CTKD7'] == province) & 
                (self.df[kpi_column].notna()) &
                (self.df[kpi_column] != 0)  # B·ªè qua ng√†y c√≥ KPI = 0
            ].copy()
            
            if len(province_data) < 2:
                continue
            
            # S·∫Øp x·∫øp theo ng√†y
            province_data = province_data.sort_values('Ngay7')
            
            # L·∫•y ng√†y g·∫ßn nh·∫•t
            latest_date = province_data['Ngay7'].max()
            latest_value = province_data[province_data['Ngay7'] == latest_date][kpi_column].values[0]
            
            # B·ªè qua n·∫øu gi√° tr·ªã g·∫ßn nh·∫•t = 0
            if latest_value == 0:
                continue
            
            # L·∫•y gi√° tr·ªã so s√°nh (lookback_days tr∆∞·ªõc)
            compare_date = latest_date - timedelta(days=lookback_days)
            # B·ªè qua c√°c ng√†y c√≥ KPI = 0 trong period so s√°nh
            compare_data = province_data[
                (province_data['Ngay7'] <= compare_date) &
                (province_data[kpi_column].notna()) &
                (province_data[kpi_column] != 0)  # B·ªè qua gi√° tr·ªã 0
            ]
            
            if len(compare_data) == 0:
                continue
            
            # L·∫•y gi√° tr·ªã trung b√¨nh c·ªßa period tr∆∞·ªõc (ch·ªâ t√≠nh c√°c ng√†y c√≥ KPI > 0)
            compare_value = compare_data[kpi_column].mean()
            
            # ƒê√°nh gi√° xu h∆∞·ªõng x·∫•u ƒëi theo h∆∞·ªõng KPI
            if compare_value > 0:
                is_worse, change_pct = self._is_worsening(latest_value, compare_value, kpi_rule)
                limit_breached = self._is_limit_breached(latest_value, kpi_rule)

                should_alert = False
                if kpi_rule and limit_breached is not None:
                    # Ch·ªâ alert khi V·ª™A x·∫•u ƒëi V·ª™A vi ph·∫°m ng∆∞·ª°ng
                    if is_worse and abs(change_pct) >= threshold and limit_breached:
                        should_alert = True
                else:
                    # Kh√¥ng c√≥ rule ‚Üí d√πng logic c≈© theo higher_better
                    if is_worse and abs(change_pct) >= threshold:
                        should_alert = True

                if should_alert:
                    # map decline_pct v·ªÅ h∆∞·ªõng ‚Äúx·∫•u ƒëi‚Äù √¢m nh∆∞ tr∆∞·ªõc ƒë·ªÉ gi·ªØ t∆∞∆°ng th√≠ch
                    decline_like_pct = -abs(change_pct)
                    alert = {
                        'province': province,
                        'kpi': kpi_column,
                        'latest_date': latest_date,
                        'latest_value': latest_value,
                        'compare_value': compare_value,
                        'decline_pct': round(decline_like_pct, 2),
                        'severity': self._get_severity(decline_like_pct),
                        'days_lookback': lookback_days,
                        'limit': kpi_rule.get('limit') if kpi_rule else None,
                        'limit_breached': bool(limit_breached) if limit_breached is not None else None,
                        'direction': kpi_rule.get('direction') if kpi_rule else 'higher_better'
                    }
                    alerts.append(alert)
        
        # S·∫Øp x·∫øp theo m·ª©c ƒë·ªô suy gi·∫£m
        alerts.sort(key=lambda x: x['decline_pct'])
        
        print(f"   ‚ö†Ô∏è  Ph√°t hi·ªán {len(alerts)} t·ªânh c√≥ suy gi·∫£m")
        
        return alerts
    
    def _get_severity(self, decline_pct: float) -> str:
        """X√°c ƒë·ªãnh m·ª©c ƒë·ªô nghi√™m tr·ªçng"""
        if decline_pct < -10:
            return 'C·ª±c k·ª≥ nghi√™m tr·ªçng'
        elif decline_pct < -5:
            return 'Nghi√™m tr·ªçng'
        elif decline_pct < -2:
            return 'C·∫£nh b√°o'
        else:
            return 'Nh·∫π'
    
    def analyze_all_kpis(self) -> Dict[str, List[Dict]]:
        """Ph√¢n t√≠ch t·∫•t c·∫£ KPI quan tr·ªçng"""
        print("\n" + "="*60)
        print("üìä PH√ÇN T√çCH T·∫§T C·∫¢ KPI QUAN TR·ªåNG")
        print("="*60)
        
        all_alerts = {}
        
        for kpi in self.config['critical_kpis']:
            if kpi not in self.df.columns:
                print(f"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y c·ªôt: {kpi}")
                continue
            
            alerts = self.detect_declines(kpi)
            if alerts:
                all_alerts[kpi] = alerts
        
        self.decline_alerts = all_alerts
        return all_alerts
    
    def generate_decline_report(self) -> pd.DataFrame:
        """T·∫°o b√°o c√°o t·ªïng h·ª£p c√°c suy gi·∫£m"""
        if not self.decline_alerts:
            print("‚ÑπÔ∏è  Kh√¥ng c√≥ suy gi·∫£m n√†o ƒë∆∞·ª£c ph√°t hi·ªán")
            return None
        
        # T·∫°o DataFrame t·ª´ alerts
        report_data = []
        for kpi, alerts in self.decline_alerts.items():
            for alert in alerts:
                report_data.append({
                    'KPI': kpi,
                    'T·ªânh': alert['province'],
                    'Ng√†y': alert['latest_date'].strftime('%d/%m/%Y'),
                    'Gi√° tr·ªã hi·ªán t·∫°i': round(alert['latest_value'], 2),
                    'Gi√° tr·ªã tr∆∞·ªõc': round(alert['compare_value'], 2),
                    'Suy gi·∫£m (%)': alert['decline_pct'],
                    'M·ª©c ƒë·ªô': alert['severity']
                })
        
        report_df = pd.DataFrame(report_data)
        report_df = report_df.sort_values('Suy gi·∫£m (%)')
        
        return report_df
    
    def create_trend_charts(self, kpi_column: str, provinces: List[str] = None, 
                           output_path: str = None, lookback_days: int = None,
                           start_date: str = None, end_date: str = None,
                           exclude_dates: List[str] = None,
                           date_range_filter: tuple = None):
        """
        T·∫°o line chart nh∆∞ pivot chart ƒë·ªÉ xem trend
        
        Args:
            kpi_column: T√™n c·ªôt KPI
            provinces: Danh s√°ch t·ªânh (None = t·∫•t c·∫£)
            output_path: ƒê∆∞·ªùng d·∫´n l∆∞u chart
            lookback_days: S·ªë ng√†y g·∫ßn nh·∫•t ƒë·ªÉ highlight (None = d√πng t·ª´ config)
            start_date: Ng√†y b·∫Øt ƒë·∫ßu highlight (format: 'DD/MM/YYYY' ho·∫∑c 'YYYY-MM-DD') - ∆∞u ti√™n h∆°n lookback_days
            end_date: Ng√†y k·∫øt th√∫c highlight (format: 'DD/MM/YYYY' ho·∫∑c 'YYYY-MM-DD') - ∆∞u ti√™n h∆°n lookback_days
        """
        print(f"\nüìà ƒêang t·∫°o trend chart cho {kpi_column}...")
        
        # L·∫•y lookback_days t·ª´ config n·∫øu kh√¥ng ƒë∆∞·ª£c truy·ªÅn v√†o
        if lookback_days is None and not start_date and not end_date:
            lookback_days = self.config['days_lookback']
        
        # S·ª≠ d·ª•ng visualization module n·∫øu c√≥
        if KPIVisualization:
            viz = KPIVisualization(output_dir=self.config['charts_dir'])
            # Truy·ªÅn ng∆∞·ª°ng n·∫øu c√≥
            kpi_rule = self._get_kpi_rule(kpi_column)
            threshold_line = (kpi_rule.get('limit') if kpi_rule and 'limit' in kpi_rule else None)
            lower_better = (kpi_rule.get('direction') == 'lower_better') if kpi_rule else None
            fig, ax = viz.create_pivot_line_chart(
                df=self.df,
                kpi_column=kpi_column,
                group_by='CTKD7',
                provinces=provinces,
                lookback_days=lookback_days,
                start_date=start_date,
                end_date=end_date,
                exclude_dates=exclude_dates,
                date_range_filter=date_range_filter,
                threshold_line=threshold_line,
                lower_better=lower_better
            )
            filename = f"trend_{kpi_column}_{datetime.now().strftime('%Y%m%d')}.png"
            return viz.save_chart(fig, filename)
        else:
            # Fallback: t·ª± t·∫°o chart
            df_filtered = self.df.copy()
            if provinces:
                df_filtered = df_filtered[df_filtered['CTKD7'].isin(provinces)]
            
            # T√≠nh trend
            trend_data = self.calculate_trends(kpi_column)
            
            if provinces:
                trend_data = trend_data[trend_data['CTKD7'].isin(provinces)]
            
            # T·∫°o chart ƒë·∫πp h∆°n
            fig, ax = plt.subplots(figsize=(18, 10))
            
            # M√†u s·∫Øc ƒë·∫πp h∆°n
            colors = plt.cm.tab10(range(len(trend_data['CTKD7'].unique())))
            
            # Plot t·ª´ng t·ªânh v·ªõi styling ƒë·∫πp
            for idx, province in enumerate(trend_data['CTKD7'].unique()):
                province_trend = trend_data[trend_data['CTKD7'] == province]
                ax.plot(province_trend['Ngay7'], province_trend[kpi_column], 
                        marker='o', label=province, 
                        linewidth=3.5, markersize=12,
                        alpha=0.9, markerfacecolor='white',
                        markeredgewidth=2.5, color=colors[idx])
            
            # Format ng√†y
            from matplotlib.dates import DateFormatter, DayLocator
            from matplotlib.ticker import MaxNLocator, FuncFormatter
            ax.xaxis.set_major_locator(DayLocator(interval=1))
            ax.xaxis.set_major_formatter(DateFormatter('%d/%m/%Y'))
            ax.yaxis.set_major_locator(MaxNLocator(nbins=20))
            
            def format_y_axis(value, pos):
                return f'{value:.2f}'
            ax.yaxis.set_major_formatter(FuncFormatter(format_y_axis))
            
            ax.set_title(f'Trend Analysis: {kpi_column} theo T·ªânh', 
                        fontsize=18, fontweight='bold', pad=25, color='#2c3e50')
            ax.set_xlabel('Ng√†y', fontsize=14, fontweight='bold', color='#34495e', labelpad=15)
            ax.set_ylabel(kpi_column, fontsize=14, fontweight='bold', color='#34495e', labelpad=15)
            
            # Legend ƒë·∫πp h∆°n
            ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', 
                     fontsize=11, framealpha=0.95, 
                     edgecolor='#34495e', fancybox=True, shadow=True)
            
            # Grid ƒë·∫πp h∆°n
            ax.grid(True, alpha=0.4, linestyle='--', which='major', color='#95a5a6', linewidth=1.2)
            ax.grid(True, alpha=0.2, linestyle=':', which='minor', color='#bdc3c7')
            
            # Spines
            ax.spines['top'].set_visible(False)
            ax.spines['right'].set_visible(False)
            ax.spines['left'].set_color('#34495e')
            ax.spines['left'].set_linewidth(2)
            ax.spines['bottom'].set_color('#34495e')
            ax.spines['bottom'].set_linewidth(2)
            
            ax.set_facecolor('#ffffff')
            fig.patch.set_facecolor('#ffffff')
            
            plt.xticks(rotation=45, ha='right', fontsize=11)
            plt.yticks(fontsize=11)
            plt.tight_layout(rect=[0, 0, 0.96, 1])
            
            # L∆∞u chart
            if output_path is None:
                output_path = f"{self.config['charts_dir']}/trend_{kpi_column}_{datetime.now().strftime('%Y%m%d')}.png"
            
            import os
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            plt.savefig(output_path, dpi=300, bbox_inches='tight')
            print(f"‚úÖ ƒê√£ l∆∞u chart: {output_path}")
            
            plt.close()
            return output_path

    def create_trend_charts_interactive(self, kpi_column: str, provinces: List[str] = None,
                                         exclude_dates: List[str] = None,
                                         date_range_filter: tuple = None,
                                         output_filename: str = None):
        """Ch·∫ø ƒë·ªô t∆∞∆°ng t√°c: click ƒë·ªÉ lo·∫°i b·ªè ng√†y v√† l∆∞u b·∫±ng ph√≠m 's'."""
        if KPIVisualization is None:
            print("‚ö†Ô∏è  Visualization module kh√¥ng kh·∫£ d·ª•ng")
            return None
        viz = KPIVisualization(output_dir=self.config['charts_dir'])
        fig, ax = viz.interactive_pivot_line_chart(
            df=self.df,
            kpi_column=kpi_column,
            group_by='CTKD7',
            provinces=provinces,
            exclude_dates=exclude_dates,
            date_range_filter=date_range_filter,
            output_filename=output_filename
        )
        return fig
    
    def should_fetch_district_data(self, province: str, kpi: str) -> bool:
        """
        Quy·∫øt ƒë·ªãnh c√≥ c·∫ßn t·∫£i d·ªØ li·ªáu c·∫•p huy·ªán kh√¥ng
        
        Logic: N·∫øu t·ªânh c√≥ suy gi·∫£m nghi√™m tr·ªçng ‚Üí c·∫ßn drill down
        """
        if kpi not in self.decline_alerts:
            return False
        
        # Ki·ªÉm tra xem t·ªânh c√≥ trong alert kh√¥ng
        for alert in self.decline_alerts[kpi]:
            if alert['province'] == province and alert['severity'] in ['Nghi√™m tr·ªçng', 'C·ª±c k·ª≥ nghi√™m tr·ªçng']:
                return True
        
        return False
    
    def get_provinces_needing_district_data(self) -> List[Dict]:
        """L·∫•y danh s√°ch t·ªânh c·∫ßn t·∫£i d·ªØ li·ªáu huy·ªán"""
        provinces_needing = []
        
        for kpi, alerts in self.decline_alerts.items():
            for alert in alerts:
                if alert['severity'] in ['Nghi√™m tr·ªçng', 'C·ª±c k·ª≥ nghi√™m tr·ªçng']:
                    provinces_needing.append({
                        'province': alert['province'],
                        'kpi': kpi,
                        'decline_pct': alert['decline_pct'],
                        'severity': alert['severity']
                    })
        
        # Remove duplicates
        seen = set()
        unique_list = []
        for item in provinces_needing:
            key = (item['province'], item['kpi'])
            if key not in seen:
                seen.add(key)
                unique_list.append(item)
        
        return unique_list


class DistrictDataFetcher:
    """Class ƒë·ªÉ t·∫£i d·ªØ li·ªáu c·∫•p huy·ªán"""
    
    def __init__(self, api_endpoint: str = None, file_path: str = None):
        self.api_endpoint = api_endpoint
        self.file_path = file_path
    
    def fetch_district_data(self, province: str, date: datetime = None) -> pd.DataFrame:
        """
        T·∫£i d·ªØ li·ªáu c·∫•p huy·ªán cho t·ªânh
        
        Args:
            province: T√™n t·ªânh
            date: Ng√†y c·∫ßn l·∫•y d·ªØ li·ªáu (None = ng√†y g·∫ßn nh·∫•t)
        
        Returns:
            DataFrame v·ªõi d·ªØ li·ªáu huy·ªán
        """
        print(f"\nüì• ƒêang t·∫£i d·ªØ li·ªáu c·∫•p huy·ªán cho {province}...")
        
        # TODO: Implement actual data fetching logic
        # C√≥ th·ªÉ:
        # 1. G·ªçi API ƒë·ªÉ l·∫•y d·ªØ li·ªáu
        # 2. ƒê·ªçc t·ª´ file CSV kh√°c
        # 3. Query t·ª´ database
        
        # Placeholder: T·∫°o mock data structure
        # Trong th·ª±c t·∫ø, b·∫°n s·∫Ω implement logic fetch th·∫≠t
        
        print(f"‚ö†Ô∏è  C·∫ßn implement logic fetch d·ªØ li·ªáu huy·ªán")
        print(f"   - Province: {province}")
        print(f"   - Date: {date or 'Latest'}")
        
        # V√≠ d·ª• c·∫•u tr√∫c d·ªØ li·ªáu huy·ªán
        district_data_structure = {
            'Ngay7': [],
            'Tinh': [],
            'Huyen': [],
            'MTCL_2024': [],
            'CSSR': [],
            'CDR': [],
            # ... c√°c KPI kh√°c
        }
        
        return pd.DataFrame(district_data_structure)
    
    def analyze_district_decline(self, district_df: pd.DataFrame, 
                                 kpi: str) -> pd.DataFrame:
        """Ph√¢n t√≠ch suy gi·∫£m theo huy·ªán"""
        print(f"\nüîç ƒêang ph√¢n t√≠ch suy gi·∫£m theo huy·ªán cho {kpi}...")
        
        # Group by huy·ªán v√† t√≠nh trend
        district_analysis = district_df.groupby('Huyen').agg({
            kpi: ['mean', 'min', 'max', 'count']
        }).reset_index()
        
        district_analysis.columns = ['Huyen', 'mean', 'min', 'max', 'count']
        
        # S·∫Øp x·∫øp theo mean (t·ª´ th·∫•p nh·∫•t)
        district_analysis = district_analysis.sort_values('mean')
        
        return district_analysis


def main():
    """H√†m ch√≠nh ch·∫°y pipeline"""
    print("="*60)
    print("üöÄ PIPELINE PH√ÅT HI·ªÜN SUY GI·∫¢M KPI")
    print("="*60)
    
    # Kh·ªüi t·∫°o detector
    detector = KPIDeclineDetector('1.Ng√†y.csv')
    
    # Step 1: Load v√† clean data
    detector.load_and_clean_data()
    
    # Step 2: Ph√¢n t√≠ch t·∫•t c·∫£ KPI quan tr·ªçng
    all_alerts = detector.analyze_all_kpis()
    
    # Step 3: T·∫°o b√°o c√°o
    if all_alerts:
        report_df = detector.generate_decline_report()
        print("\n" + "="*60)
        print("üìã B√ÅO C√ÅO SUY GI·∫¢M KPI")
        print("="*60)
        print(report_df.to_string(index=False))
        
        # L∆∞u b√°o c√°o (an to√†n khi file ƒëang b·ªã m·ªü/kh√≥a b·ªüi Excel)
        import os
        date_str = datetime.now().strftime('%Y%m%d')
        os.makedirs('reports', exist_ok=True)
        report_path = f"reports/decline_report_{date_str}.csv"
        try:
            report_df.to_csv(report_path, index=False, encoding='utf-8-sig')
            print(f"\n‚úÖ ƒê√£ l∆∞u b√°o c√°o: {report_path}")
        except PermissionError:
            # Ghi sang th∆∞ m·ª•c theo ng√†y v·ªõi t√™n c√≥ timestamp ƒë·ªÉ tr√°nh xung ƒë·ªôt kh√≥a file
            dated_dir = os.path.join('reports', date_str)
            os.makedirs(dated_dir, exist_ok=True)
            ts = datetime.now().strftime('%H%M%S')
            alt_path = os.path.join(dated_dir, f"decline_report_{date_str}_{ts}.csv")
            report_df.to_csv(alt_path, index=False, encoding='utf-8-sig')
            print(f"\n‚ö†Ô∏è  File {report_path} ƒëang b·ªã kh√≥a (c√≥ th·ªÉ ƒëang m·ªü trong Excel).\n   ‚Üí ƒê√£ l∆∞u t·∫°m v√†o: {alt_path}")
    else:
        print("\n‚úÖ Kh√¥ng ph√°t hi·ªán suy gi·∫£m nghi√™m tr·ªçng n√†o")
    
    # Step 4: T·∫°o trend charts cho c√°c KPI c√≥ v·∫•n ƒë·ªÅ
    print("\n" + "="*60)
    print("üìä T·∫†O TREND CHARTS")
    print("="*60)
    
    for kpi in detector.config['critical_kpis']:
        if kpi in all_alerts and all_alerts[kpi]:
            # L·∫•y danh s√°ch t·ªânh c√≥ v·∫•n ƒë·ªÅ
            provinces_with_issues = [alert['province'] for alert in all_alerts[kpi]]
            detector.create_trend_charts(kpi, provinces_with_issues)
    
    # Step 5: G·ª≠i alerts
    if AlertSystem:
        print("\n" + "="*60)
        print("üì¢ G·ª¨I ALERTS")
        print("="*60)
        
        alert_system = AlertSystem()
        
        # G·ª≠i alerts cho t·∫•t c·∫£ suy gi·∫£m
        for kpi, alerts in all_alerts.items():
            for alert in alerts:
                alert_system.send_decline_alert(
                    province=alert['province'],
                    kpi=alert['kpi'],
                    decline_pct=alert['decline_pct'],
                    latest_value=alert['latest_value'],
                    compare_value=alert['compare_value']
                )
    
    # Step 6: X√°c ƒë·ªãnh t·ªânh c·∫ßn t·∫£i d·ªØ li·ªáu huy·ªán
    print("\n" + "="*60)
    print("üì• X√ÅC ƒê·ªäNH T·ªàNH C·∫¶N D·ªÆ LI·ªÜU HUY·ªÜN")
    print("="*60)
    
    provinces_needing = detector.get_provinces_needing_district_data()
    
    if provinces_needing:
        print(f"\n‚ö†Ô∏è  C√≥ {len(provinces_needing)} t·ªânh c·∫ßn t·∫£i d·ªØ li·ªáu huy·ªán:")
        for item in provinces_needing:
            print(f"   - {item['province']}: {item['kpi']} (suy gi·∫£m {item['decline_pct']}%)")
        
        # Kh·ªüi t·∫°o fetcher
        fetcher = DistrictDataFetcher()
        
        # T·∫£i d·ªØ li·ªáu cho t·ª´ng t·ªânh
        for item in provinces_needing:
            district_data = fetcher.fetch_district_data(
                item['province'],
                datetime.now()
            )
            
            # Ph√¢n t√≠ch suy gi·∫£m theo huy·ªán
            if len(district_data) > 0:
                district_analysis = fetcher.analyze_district_decline(
                    district_data, 
                    item['kpi']
                )
                print(f"\nüìä Top 5 huy·ªán c√≥ v·∫•n ƒë·ªÅ ·ªü {item['province']}:")
                print(district_analysis.head().to_string(index=False))
    else:
        print("\n‚úÖ Kh√¥ng c√≥ t·ªânh n√†o c·∫ßn t·∫£i d·ªØ li·ªáu huy·ªán")
    
    print("\n" + "="*60)
    print("‚úÖ Pipeline ho√†n th√†nh!")
    print("="*60)
    
    return detector, all_alerts


if __name__ == "__main__":
    detector, alerts = main()

