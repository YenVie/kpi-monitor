"""
SCRIPT PH√ÇN T√çCH T·ªîNG QU√ÅT: B·∫•t k·ª≥ t·ªânh n√†o v√† KPI n√†o
======================================================
Cho ph√©p ph√¢n t√≠ch suy gi·∫£m cho b·∫•t k·ª≥ t·ªânh v√† KPI n√†o

S·ª≠ d·ª•ng Git ƒë·ªÉ qu·∫£n l√Ω phi√™n b·∫£n code.
Version: 1.0

[T·∫†O THAY ƒê·ªîI ƒê·ªÇ TH·ª∞C H√ÄNH GIT] - B·∫°n c√≥ th·ªÉ x√≥a d√≤ng n√†y sau khi h·ªçc xong
"""

import pandas as pd
import sys
from datetime import datetime
from typing import List
from kpi_decline_detection_pipeline import KPIDeclineDetector
from visualization_module import KPIVisualization

def _normalize_token(text: str) -> str:
    """Chu·∫©n h√≥a t√™n KPI ƒë·ªÉ so kh·ªõp: b·ªè kho·∫£ng tr·∫Øng, d·∫•u g·∫°ch, g·∫°ch d∆∞·ªõi v√† vi·∫øt hoa."""
    import re
    return re.sub(r"[^A-Z0-9]", "", str(text).upper())

def fuzzy_match_kpi(kpi_input: str, columns: list) -> tuple:
    """Tr·∫£ v·ªÅ (matched_kpi, candidates)
    ∆Øu ti√™n: exact (case-insensitive) ‚Üí exact-normalized ‚Üí startswith ‚Üí contains.
    N·∫øu c√≥ nhi·ªÅu candidates, gi·ªØ nguy√™n danh s√°ch ƒë·ªÉ hi·ªÉn th·ªã cho ng∆∞·ªùi d√πng.
    """
    if not kpi_input:
        return None, []
    k_in = str(kpi_input)
    cols = [str(c) for c in columns]
    up = k_in.upper()
    norm_in = _normalize_token(k_in)

    # 1) exact (case-insensitive)
    for c in cols:
        if up == str(c).upper():
            return c, [c]
    # 2) exact normalized (handle VN-CSSR vs VN_CSSR)
    exact_norm = [c for c in cols if _normalize_token(c) == norm_in]
    if len(exact_norm) == 1:
        return exact_norm[0], exact_norm
    if len(exact_norm) > 1:
        return exact_norm[0], exact_norm
    # 3) startswith
    starts = [c for c in cols if str(c).upper().startswith(up)]
    if len(starts) == 1:
        return starts[0], starts
    # 4) contains (∆∞u ti√™n ch·ª©a nguy√™n c·ª•m VN n·∫øu input c√≥ VN)
    cont = [c for c in cols if up in str(c).upper() or str(c).upper() in up]
    if len(cont) == 1:
        return cont[0], cont
    if len(cont) > 1:
        # ∆Øu ti√™n c·ªôt c√≥ token 'VN' n·∫øu input c√≥ 'VN'
        if 'VN' in up:
            vn_first = [c for c in cont if 'VN' in str(c).upper()]
            if vn_first:
                return vn_first[0], cont
        # ∆Øu ti√™n t√™n d√†i h∆°n (th∆∞·ªùng c·ª• th·ªÉ h∆°n)
        cont_sorted = sorted(cont, key=lambda x: len(str(x)), reverse=True)
        return cont_sorted[0], cont
    return None, []

def analyze_province_kpi(province_name: str, kpi_name: str, 
                         file_path: str = '1.Ng√†y.csv',
                         lookback_days: int = 7,
                         decline_threshold: float = 2.0,
                         start_date: str = None,
                         end_date: str = None):
    """
    Ph√¢n t√≠ch suy gi·∫£m KPI cho m·ªôt t·ªânh c·ª• th·ªÉ
    
    Args:
        province_name: T√™n t·ªânh (v√≠ d·ª•: 'Ninh thuan', 'Tp Ho Chi Minh')
        kpi_name: T√™n KPI (v√≠ d·ª•: 'HOSR_4G_2024', 'MTCL_2024', 'CSSR')
        file_path: ƒê∆∞·ªùng d·∫´n file CSV
        lookback_days: S·ªë ng√†y g·∫ßn nh·∫•t ƒë·ªÉ so s√°nh (ch·ªâ d√πng n·∫øu kh√¥ng c√≥ start_date/end_date)
        decline_threshold: Ng∆∞·ª°ng suy gi·∫£m (%)
        start_date: Ng√†y b·∫Øt ƒë·∫ßu so s√°nh (format: 'DD/MM/YYYY' ho·∫∑c 'YYYY-MM-DD') - ∆∞u ti√™n h∆°n lookback_days
        end_date: Ng√†y k·∫øt th√∫c so s√°nh (format: 'DD/MM/YYYY' ho·∫∑c 'YYYY-MM-DD') - ∆∞u ti√™n h∆°n lookback_days
    """
    print("="*60)
    print(f"üîç PH√ÇN T√çCH: {province_name} - {kpi_name}")
    print("="*60)
    
    # Step 1: Load data
    print("\nüìñ B∆∞·ªõc 1: ƒêang load d·ªØ li·ªáu...")
    detector = KPIDeclineDetector(file_path)
    df = detector.load_and_clean_data()
    
    # Step 2: Ki·ªÉm tra t·ªânh c√≥ trong data kh√¥ng
    print(f"\nüîç B∆∞·ªõc 2: Ki·ªÉm tra t·ªânh '{province_name}'...")
    all_provinces = df['CTKD7'].unique()
    all_provinces_clean = [p for p in all_provinces if pd.notna(p)]
    
    # T√¨m t·ªânh (case-insensitive, c√≥ th·ªÉ vi·∫øt t·∫Øt)
    matched_province = None
    for p in all_provinces_clean:
        if province_name.lower() in p.lower() or p.lower() in province_name.lower():
            matched_province = p
            break
    
    if matched_province is None:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y t·ªânh '{province_name}'!")
        print(f"\nüìã Danh s√°ch t·ªânh c√≥ trong file:")
        for i, p in enumerate(sorted(all_provinces_clean), 1):
            print(f"   {i}. {p}")
        return None
    
    print(f"‚úÖ T√¨m th·∫•y: {matched_province}")
    province_data = df[df['CTKD7'] == matched_province].copy()
    print(f"   S·ªë d√≤ng d·ªØ li·ªáu: {len(province_data)}")
    
    # Step 3: Ki·ªÉm tra KPI c√≥ trong data kh√¥ng (t·ª± ƒë·ªông t√¨m g·∫ßn ƒë√∫ng)
    print(f"\nüîç B∆∞·ªõc 3: Ki·ªÉm tra KPI '{kpi_name}'...")
    
    # T√¨m KPI ch√≠nh x√°c ho·∫∑c g·∫ßn ƒë√∫ng (∆∞u ti√™n exact/normalized)
    matched_kpi, kpi_candidates = fuzzy_match_kpi(kpi_name, list(df.columns))
    
    if matched_kpi is None:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y KPI '{kpi_name}'!")
        print(f"\nüìã Danh s√°ch KPI c√≥ trong file (m·ªôt ph·∫ßn):")
        kpi_cols = [c for c in df.columns if any(keyword in c.upper() 
                   for keyword in ['MTCL', 'CSSR', 'CDR', 'HOSR', 'ERAB', 'DATA', 'VN', 'QOS', 'SR', 'DR'])]
        for i, kpi in enumerate(sorted(kpi_cols)[:30], 1):
            print(f"   {i}. {kpi}")
        print(f"\nüí° Tip: B·∫°n c√≥ th·ªÉ nh·∫≠p m·ªôt ph·∫ßn t√™n KPI, v√≠ d·ª•: 'HOSR' s·∫Ω t√¨m 'HOSR_4G_2024'")
        return None
    
    if matched_kpi != kpi_name:
        print(f"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y '{kpi_name}', d√πng KPI kh·ªõp t·ªët nh·∫•t: '{matched_kpi}'")
        if len(kpi_candidates) > 1:
            print("   ·ª®ng vi√™n kh√°c:")
            for c in kpi_candidates[:10]:
                if c != matched_kpi:
                    print(f"   - {c}")
    else:
        print(f"‚úÖ T√¨m th·∫•y KPI: {matched_kpi}")
    
    kpi_name = matched_kpi  # C·∫≠p nh·∫≠t ƒë·ªÉ d√πng t√™n ch√≠nh x√°c
    
    # Step 4: Ph√¢n t√≠ch suy gi·∫£m
    print(f"\nüîç B∆∞·ªõc 4: Ph√¢n t√≠ch suy gi·∫£m...")
    alerts = detector.detect_declines(kpi_name, lookback_days=lookback_days)
    
    # L·ªçc alerts cho t·ªânh n√†y
    province_alerts = [a for a in alerts if a['province'] == matched_province]
    
    if province_alerts:
        print(f"\n‚ö†Ô∏è  PH√ÅT HI·ªÜN SUY GI·∫¢M!")
        for alert in province_alerts:
            print(f"\n   T·ªânh: {alert['province']}")
            print(f"   KPI: {alert['kpi']}")
            print(f"   Ng√†y: {alert['latest_date'].strftime('%d/%m/%Y')}")
            print(f"   Gi√° tr·ªã hi·ªán t·∫°i: {alert['latest_value']:.2f}")
            print(f"   Gi√° tr·ªã tr∆∞·ªõc ({alert['days_lookback']} ng√†y): {alert['compare_value']:.2f}")
            print(f"   Suy gi·∫£m: {alert['decline_pct']:.2f}%")
            print(f"   M·ª©c ƒë·ªô: {alert['severity']}")
    else:
        print(f"\n‚úÖ Kh√¥ng ph√°t hi·ªán suy gi·∫£m m·∫°nh cho {matched_province}")
        print(f"   (c√≥ th·ªÉ suy gi·∫£m < {decline_threshold}% ho·∫∑c kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªß)")
    
    # Step 5: T·∫°o trend chart v·ªõi lookback_days ho·∫∑c ng√†y c·ª• th·ªÉ
    if start_date and end_date:
        print(f"\nüìà B∆∞·ªõc 5: T·∫°o trend chart (highlight t·ª´ {start_date} ƒë·∫øn {end_date})...")
    else:
        print(f"\nüìà B∆∞·ªõc 5: T·∫°o trend chart (so s√°nh {lookback_days} ng√†y g·∫ßn nh·∫•t)...")
    try:
        # C·∫≠p nh·∫≠t config ƒë·ªÉ d√πng lookback_days ƒë√∫ng (n·∫øu kh√¥ng c√≥ ng√†y c·ª• th·ªÉ)
        if not start_date or not end_date:
            detector.config['days_lookback'] = lookback_days
        
        chart_path = detector.create_trend_charts(
            kpi_name,
            provinces=[matched_province],
            lookback_days=lookback_days if not start_date or not end_date else None,
            start_date=start_date,
            end_date=end_date
        )
        print(f"‚úÖ ƒê√£ t·∫°o chart: {chart_path}")
        if start_date and end_date:
            print(f"   Chart highlight kho·∫£ng: {start_date} - {end_date}")
        else:
            print(f"   Chart highlight {lookback_days} ng√†y g·∫ßn nh·∫•t")
    except Exception as e:
        print(f"‚ö†Ô∏è  L·ªói khi t·∫°o chart: {str(e)}")
    
    # Step 6: Th·ªëng k√™
    print(f"\nüìä B∆∞·ªõc 6: Th·ªëng k√™ {kpi_name} c·ªßa {matched_province}...")
    # QUAN TR·ªåNG: B·ªè qua c√°c ng√†y c√≥ KPI = 0 ho·∫∑c null khi t√≠nh th·ªëng k√™
    province_kpi_data = province_data[['Ngay7', kpi_name]].copy()
    province_kpi_data = province_kpi_data.sort_values('Ngay7')
    province_kpi_data = province_kpi_data[
        (province_kpi_data[kpi_name].notna()) & 
        (province_kpi_data[kpi_name] != 0)  # B·ªè qua ng√†y c√≥ KPI = 0
    ]
    
    if len(province_kpi_data) > 0:
        stats = {
            'Min': province_kpi_data[kpi_name].min(),
            'Max': province_kpi_data[kpi_name].max(),
            'Mean': province_kpi_data[kpi_name].mean(),
            'Latest': province_kpi_data[kpi_name].iloc[-1],
            'First': province_kpi_data[kpi_name].iloc[0],
            'Count': len(province_kpi_data)
        }
        
        print(f"\n   S·ªë ƒëi·ªÉm d·ªØ li·ªáu: {stats['Count']}")
        print(f"   Min: {stats['Min']:.2f}")
        print(f"   Max: {stats['Max']:.2f}")
        print(f"   Mean: {stats['Mean']:.2f}")
        print(f"   First (ƒë·∫ßu): {stats['First']:.2f}")
        print(f"   Latest (cu·ªëi): {stats['Latest']:.2f}")
        
        total_change = ((stats['Latest'] - stats['First']) / stats['First']) * 100
        print(f"   Thay ƒë·ªïi t·ªïng: {total_change:.2f}%")
    
    print("\n" + "="*60)
    print("‚úÖ Ph√¢n t√≠ch ho√†n th√†nh!")
    print("="*60)
    
    return detector, province_alerts, matched_province


def analyze_all_provinces_for_kpi(kpi_name: str, 
                                  file_path: str = '1.Ng√†y.csv',
                                  lookback_days: int = 7,
                                  start_date: str = None,
                                  end_date: str = None):
    """
    Ph√¢n t√≠ch m·ªôt KPI cho t·∫•t c·∫£ c√°c t·ªânh
    """
    print("="*60)
    print(f"üîç PH√ÇN T√çCH T·∫§T C·∫¢ T·ªàNH - KPI: {kpi_name}")
    print("="*60)
    
    detector = KPIDeclineDetector(file_path)
    df = detector.load_and_clean_data()
    
    # T√¨m KPI ch√≠nh x√°c ho·∫∑c g·∫ßn ƒë√∫ng (∆∞u ti√™n exact/normalized)
    matched_kpi, kpi_candidates = fuzzy_match_kpi(kpi_name, list(df.columns))
    
    if matched_kpi is None:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y KPI '{kpi_name}'!")
        print(f"\nüìã Danh s√°ch KPI c√≥ trong file (m·ªôt ph·∫ßn):")
        kpi_cols = [c for c in df.columns if any(keyword in c.upper() 
                   for keyword in ['MTCL', 'CSSR', 'CDR', 'HOSR', 'ERAB', 'DATA', 'VN', 'QOS', 'SR', 'DR'])]
        for i, kpi in enumerate(sorted(kpi_cols)[:30], 1):
            print(f"   {i}. {kpi}")
        return []
    
    if matched_kpi != kpi_name:
        print(f"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y '{kpi_name}', d√πng KPI kh·ªõp t·ªët nh·∫•t: '{matched_kpi}'")
        if len(kpi_candidates) > 1:
            print("   ·ª®ng vi√™n kh√°c:")
            for c in kpi_candidates[:10]:
                if c != matched_kpi:
                    print(f"   - {c}")
    
    # Ph√°t hi·ªán suy gi·∫£m cho t·∫•t c·∫£ t·ªânh
    alerts = detector.detect_declines(matched_kpi, lookback_days=lookback_days)
    
    if alerts:
        print(f"\n‚ö†Ô∏è  Ph√°t hi·ªán {len(alerts)} t·ªânh c√≥ suy gi·∫£m {matched_kpi}:")
        print("\n" + "-"*60)
        for i, alert in enumerate(alerts, 1):
            print(f"{i}. {alert['province']}: {alert['decline_pct']:.2f}% ({alert['severity']})")
        
        # T·∫°o chart cho t·∫•t c·∫£ t·ªânh c√≥ v·∫•n ƒë·ªÅ
        provinces_with_issues = [a['province'] for a in alerts]
        detector.create_trend_charts(matched_kpi, provinces=provinces_with_issues, 
                                     lookback_days=lookback_days if not start_date or not end_date else None,
                                     start_date=start_date,
                                     end_date=end_date)
    else:
        print("\n‚úÖ Kh√¥ng ph√°t hi·ªán suy gi·∫£m n√†o")
    
    return alerts


def interactive_menu():
    """
    Menu t∆∞∆°ng t√°c ƒë·ªÉ ch·ªçn t·ªânh v√† KPI
    """
    print("="*60)
    print("üìä MENU PH√ÇN T√çCH KPI")
    print("="*60)
    print("\n1. Bi·ªÉu ƒë·ªì t∆∞∆°ng t√°c: M·ªôt t·ªânh + m·ªôt KPI (click ƒë·ªÉ lo·∫°i ng√†y)")
    print("2. Bi·ªÉu ƒë·ªì t∆∞∆°ng t√°c: M·ªôt KPI cho t·∫•t c·∫£ t·ªânh (click ƒë·ªÉ lo·∫°i ng√†y)")
    print("3. Ph√¢n t√≠ch t·∫•t c·∫£ KPI quan tr·ªçng (pipeline ƒë·∫ßy ƒë·ªß)")
    print("0. Tho√°t")
    
    choice = input("\nCh·ªçn ch·ª©c nƒÉng (0-3): ").strip()
    
    if choice == '1':
        province = input("Nh·∫≠p t√™n t·ªânh: ").strip()
        kpi = input("Nh·∫≠p t√™n KPI: ").strip()
        print("\n‚û°Ô∏è  C·ª≠a s·ªï bi·ªÉu ƒë·ªì s·∫Ω m·ªü.\n - Click v√†o ƒëi·ªÉm ƒë·ªÉ ch·ªçn/b·ªè m·ªôt ng√†y\n - Nh·∫•n r ƒë·ªÉ v·∫Ω l·∫°i theo ng√†y ƒë√£ ch·ªçn\n - Nh·∫•n s ƒë·ªÉ l∆∞u chart v√† ƒë√≥ng\n - Nh·∫•n q ƒë·ªÉ tho√°t")
        # M·ªü tr·ª±c ti·∫øp ch·∫ø ƒë·ªô t∆∞∆°ng t√°c, c√≥ fuzzy matching
        local_file = '1.Ng√†y.csv'
        detector = KPIDeclineDetector(local_file)
        df_int = detector.load_and_clean_data()
        # Fuzzy match KPI
        matched_kpi = kpi
        if matched_kpi not in df_int.columns:
            kup = kpi.upper()
            for col in df_int.columns:
                if kup in str(col).upper() or str(col).upper() in kup:
                    matched_kpi = col
                    break
        # Fuzzy match province
        matched_prov = None
        for p in df_int['CTKD7'].dropna().unique():
            if province.lower() in str(p).lower() or str(p).lower() in province.lower():
                matched_prov = p
                break
        prov_list = [matched_prov] if matched_prov else None
        detector.create_trend_charts_interactive(
            matched_kpi,
            provinces=prov_list,
            exclude_dates=None,
            date_range_filter=None
        )
        
    elif choice == '2':
        kpi = input("Nh·∫≠p t√™n KPI: ").strip()
        print("\n‚û°Ô∏è  C·ª≠a s·ªï bi·ªÉu ƒë·ªì s·∫Ω m·ªü.\n - Click v√†o ƒëi·ªÉm ƒë·ªÉ ch·ªçn/b·ªè m·ªôt ng√†y\n - Nh·∫•n r ƒë·ªÉ v·∫Ω l·∫°i theo ng√†y ƒë√£ ch·ªçn\n - Nh·∫•n s ƒë·ªÉ l∆∞u chart v√† ƒë√≥ng\n - Nh·∫•n q ƒë·ªÉ tho√°t")
        local_file = '1.Ng√†y.csv'
        detector = KPIDeclineDetector(local_file)
        df_int = detector.load_and_clean_data()
        # Fuzzy match KPI
        matched_kpi = kpi
        if matched_kpi not in df_int.columns:
            kup = kpi.upper()
            for col in df_int.columns:
                if kup in str(col).upper() or str(col).upper() in kup:
                    matched_kpi = col
                    break
        # L·∫•y danh s√°ch t·ªânh c√≥ v·∫•n ƒë·ªÅ (n·∫øu c√≥) ƒë·ªÉ t·∫≠p trung
        alerts = detector.detect_declines(matched_kpi, lookback_days=7)
        provinces_with_issues = [a['province'] for a in alerts] if alerts else None
        detector.create_trend_charts_interactive(
            matched_kpi,
            provinces=provinces_with_issues,
            exclude_dates=None,
            date_range_filter=None
        )
        
    elif choice == '3':
        from kpi_decline_detection_pipeline import main
        main()
        
    elif choice == '0':
        print("T·∫°m bi·ªát!")
    else:
        print("L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá!")


if __name__ == "__main__":
    if len(sys.argv) >= 3:
        # Ch·∫°y t·ª´ command line: python analyze_any_province_kpi.py <t·ªânh> <KPI>
        province = sys.argv[1]
        kpi = sys.argv[2]
        lookback = int(sys.argv[3]) if len(sys.argv) > 3 else 7
        
        analyze_province_kpi(province, kpi, lookback_days=lookback)
    else:
        # Ch·∫°y menu t∆∞∆°ng t√°c
        interactive_menu()

