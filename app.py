"""
STREAMLIT WEB APP - GI√ÅM S√ÅT KPI
=================================
Ch·∫°y tr√™n laptop local, kh√¥ng c·∫ßn server ri√™ng!

C√°ch ch·∫°y:
1. C√†i ƒë·∫∑t: pip install streamlit
2. Ch·∫°y: streamlit run app.py
3. M·ªü tr√¨nh duy·ªát: http://localhost:8501
"""

import streamlit as st
import pandas as pd
import sys
import os
from datetime import datetime
import matplotlib.pyplot as plt
import matplotlib
import unicodedata
from matplotlib.dates import DayLocator, DateFormatter
from matplotlib.ticker import MaxNLocator, FuncFormatter
matplotlib.use('Agg')  # Backend cho Streamlit

# Import c√°c module hi·ªán c√≥
try:
    from kpi_decline_detection_pipeline import KPIDeclineDetector
    from analyze_any_province_kpi import analyze_province_kpi, fuzzy_match_kpi
except ImportError as e:
    st.error(f"‚ùå L·ªói import: {e}")
    st.stop()

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="Gi√°m s√°t KPI",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS t√πy ch·ªânh
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        padding: 1rem 0;
    }
    .info-box {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Header
st.markdown('<div class="main-header">üìä H·ªÜ TH·ªêNG GI√ÅM S√ÅT KPI</div>', unsafe_allow_html=True)

# Sidebar: Upload file v√† c·∫•u h√¨nh
st.sidebar.header("üìÅ C·∫•u h√¨nh")

# Upload file CSV
st.sidebar.subheader("üìÅ Qu·∫£n l√Ω d·ªØ li·ªáu")

# Ch·∫ø ƒë·ªô upload: Replace ho·∫∑c Append
upload_mode = st.sidebar.radio(
    "Ch·∫ø ƒë·ªô upload:",
    ["üîÑ Thay th·∫ø file (Replace)", "‚ûï G·ªôp d·ªØ li·ªáu m·ªõi (Append)"],
    help="Replace: Thay th·∫ø to√†n b·ªô file c≈©\nAppend: T·ª± ƒë·ªông g·ªôp d·ªØ li·ªáu m·ªõi v√†o file c≈© (ti·∫øt ki·ªám th·ªùi gian)",
    index=1
)

uploaded_file = st.sidebar.file_uploader(
    "Ch·ªçn file CSV d·ªØ li·ªáu KPI",
    type=['csv'],
    help="Upload file CSV ch·ª©a d·ªØ li·ªáu KPI",
    key="csv_uploader"
)

# H√†m merge d·ªØ li·ªáu m·ªõi v√†o file c≈© - GI·ªÆ NGUY√äN TH·ª® T·ª∞
def merge_data_files(old_file_path, new_file_path, output_path):
    """
    G·ªôp d·ªØ li·ªáu m·ªõi v√†o file c≈©, lo·∫°i b·ªè duplicate, GI·ªÆ NGUY√äN TH·ª® T·ª∞ BAN ƒê·∫¶U
    
    Args:
        old_file_path: ƒê∆∞·ªùng d·∫´n file c≈©
        new_file_path: ƒê∆∞·ªùng d·∫´n file m·ªõi (upload)
        output_path: ƒê∆∞·ªùng d·∫´n file output (th∆∞·ªùng l√† old_file_path)
    
    Returns:
        dict: Th√¥ng tin v·ªÅ qu√° tr√¨nh merge
    """
    try:
        # ƒê·ªçc file c≈© (n·∫øu c√≥)
        if os.path.exists(old_file_path):
            df_old = pd.read_csv(old_file_path, encoding='utf-8-sig', low_memory=False)
            # Chu·∫©n h√≥a t√™n c·ªôt
            df_old.columns = [str(c).strip() for c in df_old.columns]
            # Gi·ªØ nguy√™n th·ª© t·ª± ban ƒë·∫ßu b·∫±ng c√°ch th√™m c·ªôt index g·ªëc
            df_old['_original_index'] = range(len(df_old))
        else:
            df_old = pd.DataFrame()
        
        # ƒê·ªçc file m·ªõi
        df_new = pd.read_csv(new_file_path, encoding='utf-8-sig', low_memory=False)
        df_new.columns = [str(c).strip() for c in df_new.columns]
        
        # Ki·ªÉm tra c·ªôt b·∫Øt bu·ªôc
        required_cols = ['Ngay7', 'CTKD7']
        missing_cols = [c for c in required_cols if c not in df_new.columns]
        if missing_cols:
            raise ValueError(f"File m·ªõi thi·∫øu c·ªôt: {', '.join(missing_cols)}")
        
        # N·∫øu file c≈© r·ªóng, ch·ªâ c·∫ßn l∆∞u file m·ªõi
        if df_old.empty:
            df_merged = df_new.copy()
            duplicates_removed = 0
        else:
            # Ki·ªÉm tra c·ªôt c√≥ gi·ªëng nhau kh√¥ng
            old_cols = set(df_old.columns) - {'_original_index'}
            new_cols = set(df_new.columns)
            if old_cols != new_cols:
                # C·∫£nh b√°o nh∆∞ng v·∫´n merge v·ªõi c·ªôt chung
                common_cols = old_cols & new_cols
                st.sidebar.warning(f"‚ö†Ô∏è File c√≥ s·ªë c·ªôt kh√°c nhau. Ch·ªâ merge {len(common_cols)} c·ªôt chung.")
                df_old = df_old[list(common_cols) + ['_original_index']]
                df_new = df_new[list(common_cols)]
            
            # X·ª≠ l√Ω duplicate th√¥ng minh: gi·ªØ nguy√™n th·ª© t·ª± file c≈©
            date_col = 'Ngay7'
            province_col = 'CTKD7'
            
            if date_col in df_old.columns and date_col in df_new.columns and province_col in df_old.columns and province_col in df_new.columns:
                # Chuy·ªÉn ƒë·ªïi ng√†y ƒë·ªÉ so s√°nh
                df_old[date_col + '_parsed'] = pd.to_datetime(
                    df_old[date_col], format='%d/%m/%Y', errors='coerce'
                )
                df_new[date_col + '_parsed'] = pd.to_datetime(
                    df_new[date_col], format='%d/%m/%Y', errors='coerce'
                )
                
                # T·∫°o key ƒë·ªÉ x√°c ƒë·ªãnh duplicate: Ngay7 + CTKD7
                df_old['_merge_key'] = df_old[date_col + '_parsed'].astype(str) + '_' + df_old[province_col].astype(str)
                df_new['_merge_key'] = df_new[date_col + '_parsed'].astype(str) + '_' + df_new[province_col].astype(str)
                
                # L·∫•y c√°c key ƒë√£ c√≥ trong file c≈©
                existing_keys = set(df_old['_merge_key'].values)
                new_keys = set(df_new['_merge_key'].values)
                
                # X√°c ƒë·ªãnh d·ªØ li·ªáu m·ªõi (ch∆∞a c√≥ trong file c≈©)
                df_new_only = df_new[~df_new['_merge_key'].isin(existing_keys)].copy()
                
                # X√°c ƒë·ªãnh d·ªØ li·ªáu c·∫ßn c·∫≠p nh·∫≠t (c√≥ trong c·∫£ 2 file)
                keys_to_update = new_keys & existing_keys
                duplicates_removed = len(keys_to_update)
                
                # X·ª≠ l√Ω duplicate: thay th·∫ø d√≤ng c≈© b·∫±ng d√≤ng m·ªõi t·∫°i ƒë√∫ng v·ªã tr√≠
                if duplicates_removed > 0:
                    # L·∫•y d·ªØ li·ªáu m·ªõi c·∫ßn c·∫≠p nh·∫≠t
                    df_new_update = df_new[df_new['_merge_key'].isin(keys_to_update)].copy()
                    
                    # T·∫°o mapping t·ª´ key ƒë·∫øn d·ªØ li·ªáu m·ªõi
                    new_data_dict = {}
                    for _, row in df_new_update.iterrows():
                        key = row['_merge_key']
                        new_data_dict[key] = row
                    
                    # Thay th·∫ø d√≤ng c≈© b·∫±ng d√≤ng m·ªõi t·∫°i ƒë√∫ng v·ªã tr√≠
                    for idx in df_old.index:
                        key = df_old.loc[idx, '_merge_key']
                        if key in new_data_dict:
                            # Thay th·∫ø d√≤ng c≈© b·∫±ng d√≤ng m·ªõi, gi·ªØ nguy√™n index g·ªëc
                            new_row = new_data_dict[key].copy()
                            new_row['_original_index'] = df_old.loc[idx, '_original_index']
                            df_old.loc[idx] = new_row
                    
                    # X√≥a c√°c d√≤ng ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t kh·ªèi df_new_update ƒë·ªÉ tr√°nh tr√πng
                    df_new_update = pd.DataFrame()  # ƒê√£ x·ª≠ l√Ω xong
                
                # X√≥a c·ªôt t·∫°m t·ª´ df_old
                df_old = df_old.drop(columns=['_merge_key', date_col + '_parsed'], errors='ignore')
                
                # Th√™m d·ªØ li·ªáu m·ªõi v√†o cu·ªëi, v·ªõi index l·ªõn h∆°n ƒë·ªÉ gi·ªØ th·ª© t·ª±
                if len(df_new_only) > 0:
                    df_new_only = df_new_only.drop(columns=['_merge_key', date_col + '_parsed'], errors='ignore')
                    # Th√™m index l·ªõn ƒë·ªÉ ƒë·∫£m b·∫£o d·ªØ li·ªáu m·ªõi ·ªü cu·ªëi
                    max_old_index = df_old['_original_index'].max() if len(df_old) > 0 else -1
                    df_new_only['_original_index'] = range(max_old_index + 1, max_old_index + 1 + len(df_new_only))
                    
                    # Merge: file c≈© (ƒë√£ c·∫≠p nh·∫≠t duplicate) + d·ªØ li·ªáu m·ªõi
                    df_merged = pd.concat([df_old, df_new_only], ignore_index=True)
                else:
                    df_merged = df_old.copy()
                
                # S·∫Øp x·∫øp l·∫°i theo index g·ªëc ƒë·ªÉ gi·ªØ th·ª© t·ª± ban ƒë·∫ßu
                df_merged = df_merged.sort_values('_original_index', na_position='last')
                df_merged = df_merged.drop(columns=['_original_index'], errors='ignore')
                
            else:
                # N·∫øu kh√¥ng c√≥ c·ªôt ng√†y/t·ªânh, merge ƒë∆°n gi·∫£n v√† lo·∫°i b·ªè duplicate
                df_merged = pd.concat([df_old.drop(columns=['_original_index'], errors='ignore'), df_new], ignore_index=True)
                before_dedup = len(df_merged)
                df_merged = df_merged.drop_duplicates(keep='last')
                duplicates_removed = before_dedup - len(df_merged)
        
        # Reset l·∫°i s·ªë th·ª© t·ª± (STT) n·∫øu c√≥ - ƒê·∫æM LI√äN T·ª§C T·ª™ 1
        # T√¨m c·ªôt STT (c√≥ th·ªÉ l√† "STT", "stt", "S·ªë th·ª© t·ª±", "textbox164", ho·∫∑c c√°c bi·∫øn th·ªÉ)
        stt_cols = [c for c in df_merged.columns if any(keyword in str(c).upper() 
                   for keyword in ['STT', 'S·ªê TH·ª® T·ª∞', 'TEXTBOX164', 'TEXTBOX', 'NO', 'NUMBER', 'INDEX'])]
        
        if stt_cols:
            stt_col = stt_cols[0]  # L·∫•y c·ªôt ƒë·∫ßu ti√™n t√¨m th·∫•y
            
            # QUAN TR·ªåNG: Reset index c·ªßa DataFrame tr∆∞·ªõc khi g√°n STT
            # ƒê·∫£m b·∫£o index li√™n t·ª•c t·ª´ 0 ƒë·∫øn len-1
            df_merged = df_merged.reset_index(drop=True)
            
            # Reset l·∫°i STT cho to√†n b·ªô file ƒë√£ merge, ƒë·∫øm li√™n t·ª•c t·ª´ 1
            # S·ª≠ d·ª•ng iloc ƒë·ªÉ ƒë·∫£m b·∫£o g√°n ƒë√∫ng cho t·∫•t c·∫£ c√°c d√≤ng
            try:
                # C√°ch 1: G√°n tr·ª±c ti·∫øp b·∫±ng list
                df_merged[stt_col] = list(range(1, len(df_merged) + 1))
            except:
                try:
                    # C√°ch 2: G√°n b·∫±ng Series v·ªõi index ƒë√∫ng
                    df_merged[stt_col] = pd.Series(range(1, len(df_merged) + 1), index=df_merged.index)
                except:
                    # C√°ch 3: G√°n t·ª´ng d√≤ng m·ªôt (ch·∫≠m nh∆∞ng ch·∫Øc ch·∫Øn)
                    for i in range(len(df_merged)):
                        df_merged.iloc[i, df_merged.columns.get_loc(stt_col)] = i + 1
        
        # L∆∞u file ƒë√£ merge
        df_merged.to_csv(output_path, index=False, encoding='utf-8-sig')
        
        # Th·ªëng k√™
        stats = {
            'old_rows': len(df_old) if not df_old.empty else 0,
            'new_rows': len(df_new),
            'merged_rows': len(df_merged),
            'duplicates_removed': duplicates_removed,
            'added_rows': len(df_merged) - (len(df_old) if not df_old.empty else 0)
        }
        
        # Th·ªëng k√™ ng√†y
        if 'Ngay7' in df_merged.columns:
            df_merged['Ngay7_parsed'] = pd.to_datetime(
                df_merged['Ngay7'], format='%d/%m/%Y', errors='coerce'
            )
            stats['min_date'] = df_merged['Ngay7_parsed'].min()
            stats['max_date'] = df_merged['Ngay7_parsed'].max()
            df_merged = df_merged.drop(columns=['Ngay7_parsed'], errors='ignore')
        
        return stats
        
    except Exception as e:
        raise Exception(f"L·ªói khi merge d·ªØ li·ªáu: {str(e)}")

# Kh·ªüi t·∫°o detector v·ªõi cache nh∆∞ng c√≥ th·ªÉ clear (ƒê·ªäNH NGHƒ®A TR∆Ø·ªöC)
@st.cache_data(ttl=3600)  # Cache 1 gi·ªù, nh∆∞ng c√≥ th·ªÉ clear b·∫±ng button
def load_data(file_path):
    """Load v√† cache d·ªØ li·ªáu"""
    detector = KPIDeclineDetector(file_path)
    df = detector.load_and_clean_data()
    
    # Hi·ªÉn th·ªã th√¥ng tin d·ªØ li·ªáu
    date_col = 'Ngay7'
    if date_col in df.columns:
        df[date_col] = pd.to_datetime(df[date_col], format='%d/%m/%Y', errors='coerce')
        min_date = df[date_col].min()
        max_date = df[date_col].max()
        st.sidebar.info(f"üìÖ Kho·∫£ng th·ªùi gian: {min_date.strftime('%d/%m/%Y')} - {max_date.strftime('%d/%m/%Y')}")
    
    return detector, df

# L∆∞u file path v√† hash ƒë·ªÉ detect thay ƒë·ªïi
file_path = None
file_changed = False

# Ki·ªÉm tra xem ƒë√£ x·ª≠ l√Ω file n√†y ch∆∞a (tr√°nh v√≤ng l·∫∑p v√¥ h·∫°n)
if 'last_processed_file' not in st.session_state:
    st.session_state.last_processed_file = None
if 'last_processed_size' not in st.session_state:
    st.session_state.last_processed_size = 0

if uploaded_file is not None:
    # Ki·ªÉm tra xem file n√†y ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω ch∆∞a
    file_id = f"{uploaded_file.name}_{uploaded_file.size}"
    if st.session_state.last_processed_file == file_id:
        # File ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω, ch·ªâ c·∫ßn set file_path ƒë·ªÉ ti·∫øp t·ª•c
        file_path = '1.Ng√†y.csv'
    else:
        # L∆∞u file upload v√†o th∆∞ m·ª•c hi·ªán t·∫°i
        file_path = '1.Ng√†y.csv'
        is_append_mode = "Append" in upload_mode
        
        if is_append_mode:
            # CH·∫æ ƒê·ªò APPEND: G·ªôp d·ªØ li·ªáu m·ªõi v√†o file c≈©
            if os.path.exists(file_path):
                # L∆∞u file m·ªõi t·∫°m th·ªùi
                temp_new_file = 'temp_new_data.csv'
                with open(temp_new_file, 'wb') as f:
                    f.write(uploaded_file.getbuffer())
                
                try:
                    # Merge d·ªØ li·ªáu
                    stats = merge_data_files(file_path, temp_new_file, file_path)
                    
                    # ƒê√°nh d·∫•u ƒë√£ x·ª≠ l√Ω file n√†y
                    st.session_state.last_processed_file = file_id
                    
                    # Clear cache ƒë·ªÉ load d·ªØ li·ªáu m·ªõi
                    load_data.clear()
                    
                    # Hi·ªÉn th·ªã th√¥ng tin merge
                    st.sidebar.success("‚úÖ ƒê√£ g·ªôp d·ªØ li·ªáu m·ªõi th√†nh c√¥ng!")
                    st.sidebar.info(f"üìä **Th·ªëng k√™:**")
                    st.sidebar.info(f"  ‚Ä¢ D√≤ng c≈©: {stats['old_rows']:,}")
                    st.sidebar.info(f"  ‚Ä¢ D√≤ng m·ªõi (upload): {stats['new_rows']:,}")
                    st.sidebar.info(f"  ‚Ä¢ D√≤ng sau merge: {stats['merged_rows']:,}")
                    st.sidebar.info(f"  ‚Ä¢ D√≤ng ƒë√£ th√™m: {stats['added_rows']:,}")
                    
                    if stats['duplicates_removed'] > 0:
                        st.sidebar.warning(f"‚ö†Ô∏è ƒê√£ lo·∫°i b·ªè {stats['duplicates_removed']:,} d√≤ng tr√πng l·∫∑p (thay b·∫±ng d·ªØ li·ªáu m·ªõi)")
                    
                    if 'min_date' in stats and 'max_date' in stats:
                        min_date = stats['min_date']
                        max_date = stats['max_date']
                        if pd.notna(min_date) and pd.notna(max_date):
                            st.sidebar.info(f"üìÖ Kho·∫£ng ng√†y: {min_date.strftime('%d/%m/%Y')} - {max_date.strftime('%d/%m/%Y')}")
                    
                    file_changed = True
                    
                except Exception as e:
                    st.sidebar.error(f"‚ùå L·ªói khi g·ªôp d·ªØ li·ªáu: {str(e)}")
                    st.exception(e)
                    st.stop()
                finally:
                    # X√≥a file t·∫°m
                    if os.path.exists(temp_new_file):
                        try:
                            os.remove(temp_new_file)
                        except:
                            pass
            else:
                # Ch∆∞a c√≥ file c≈©, ch·ªâ c·∫ßn l∆∞u file m·ªõi
                with open(file_path, 'wb') as f:
                    f.write(uploaded_file.getbuffer())
                st.session_state.last_processed_file = file_id
                load_data.clear()
                st.sidebar.success(f"‚úÖ ƒê√£ t·∫°o file m·ªõi! ({uploaded_file.size:,} bytes)")
                file_changed = True
        
        if not is_append_mode:
            # CH·∫æ ƒê·ªò REPLACE: Thay th·∫ø to√†n b·ªô file c≈© (GI·ªÆ NGUY√äN CH·ª®C NƒÇNG C≈®)
            # Ki·ªÉm tra xem file c√≥ thay ƒë·ªïi kh√¥ng (d·ª±a v√†o timestamp ho·∫∑c size)
            file_changed = True
            if os.path.exists(file_path):
                old_size = os.path.getsize(file_path)
                new_size = uploaded_file.size
                if old_size != new_size:
                    file_changed = True
                else:
                    # Ki·ªÉm tra n·ªôi dung (so s√°nh hash)
                    uploaded_file.seek(0)
                    new_content = uploaded_file.read()
                    uploaded_file.seek(0)
                    
                    with open(file_path, 'rb') as f:
                        old_content = f.read()
                    
                    if new_content != old_content:
                        file_changed = True
            
            # L∆∞u file m·ªõi
            with open(file_path, 'wb') as f:
                f.write(uploaded_file.getbuffer())
            
            # ƒê√°nh d·∫•u ƒë√£ x·ª≠ l√Ω file n√†y
            st.session_state.last_processed_file = file_id
            load_data.clear()
            
            st.sidebar.success(f"‚úÖ ƒê√£ thay th·∫ø file th√†nh c√¥ng! ({uploaded_file.size:,} bytes)")
            
            # Hi·ªÉn th·ªã th√¥ng tin file
            st.sidebar.info(f"üìÑ T√™n file: {uploaded_file.name}")
            file_changed = True

# X√°c ƒë·ªãnh file_path n·∫øu ch∆∞a c√≥
if file_path is None:
    if os.path.exists('1.Ng√†y.csv'):
        file_path = '1.Ng√†y.csv'
        file_size = os.path.getsize(file_path)
        st.sidebar.success(f"‚úÖ ƒêang s·ª≠ d·ª•ng file: 1.Ng√†y.csv ({file_size:,} bytes)")
    else:
        st.sidebar.warning("‚ö†Ô∏è Ch∆∞a c√≥ file CSV. Vui l√≤ng upload file.")
        st.stop()

# C·∫•u h√¨nh
st.sidebar.subheader("‚öôÔ∏è C·∫•u h√¨nh ph√¢n t√≠ch")
lookback_days = st.sidebar.slider("S·ªë ng√†y so s√°nh", 1, 30, 7)
decline_threshold = st.sidebar.slider("Ng∆∞·ª°ng suy gi·∫£m (%)", 0.1, 10.0, 2.0, 0.1)

# N√∫t reload data
if st.sidebar.button("üîÑ Reload d·ªØ li·ªáu", help="T·∫£i l·∫°i d·ªØ li·ªáu t·ª´ file CSV"):
    load_data.clear()
    st.sidebar.success("‚úÖ ƒê√£ reload d·ªØ li·ªáu!")
    st.rerun()

try:
    detector, df = load_data(file_path)
    
    # Hi·ªÉn th·ªã th√¥ng tin d·ªØ li·ªáu ƒë√£ load
    st.sidebar.info(f"üìä S·ªë d√≤ng: {len(df):,} | S·ªë t·ªânh: {len(df['CTKD7'].dropna().unique())}")
    
except Exception as e:
    st.error(f"‚ùå L·ªói khi load d·ªØ li·ªáu: {str(e)}")
    st.exception(e)
    st.stop()

# Tab ch√≠nh
tab1, tab2, tab3, tab4 = st.tabs([
    "üìä Overview", 
    "üîç Ph√¢n t√≠ch t·ªânh", 
    "üìà T·∫•t c·∫£ t·ªânh", 
    "üö® Alerts"
])

# TAB 1: OVERVIEW
with tab1:
    st.header("üìä T·ªïng quan d·ªØ li·ªáu")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("S·ªë t·ªânh", len(df['CTKD7'].unique()))
    
    with col2:
        st.metric("S·ªë ƒëi·ªÉm d·ªØ li·ªáu", len(df))
    
    with col3:
        date_range = pd.to_datetime(df['Ngay7']).max() - pd.to_datetime(df['Ngay7']).min()
        st.metric("Kho·∫£ng th·ªùi gian", f"{date_range.days} ng√†y")
    
    with col4:
        # ƒê·∫øm s·ªë KPI (bao g·ªìm c√°c KPI m·ªõi: v√πng ph·ªß & s·ª± c·ªë)
        kpi_cols = [c for c in df.columns if any(k in c.upper() 
                   for k in ['MTCL', 'CSSR', 'CDR', 'HOSR', 'ERAB', 'DATA', 'VN', 'QOS', 'SR', 'DR', 'COVERAGE', 'CHATLUONG', 'SUCO', 'SU_CO'])]
        st.metric("S·ªë KPI", len(kpi_cols))
    
    # Hi·ªÉn th·ªã d·ªØ li·ªáu v·ªõi ph√¢n trang
    st.subheader("üìã Xem d·ªØ li·ªáu")
    
    # T√πy ch·ªçn hi·ªÉn th·ªã
    col_view1, col_view2 = st.columns(2)
    
    with col_view1:
        show_all = st.checkbox("Hi·ªÉn th·ªã to√†n b·ªô d·ªØ li·ªáu", value=False, help="B·ªè ch·ªçn ƒë·ªÉ xem t·ª´ng trang")
    
    with col_view2:
        if not show_all:
            rows_per_page = st.selectbox(
                "S·ªë d√≤ng m·ªói trang",
                options=[10, 25, 50, 100, 200],
                index=0,
                help="Ch·ªçn s·ªë d√≤ng hi·ªÉn th·ªã m·ªói trang"
            )
        else:
            rows_per_page = len(df)
    
    # Ph√¢n trang
    if not show_all and rows_per_page < len(df):
        total_rows = len(df)
        total_pages = (total_rows + rows_per_page - 1) // rows_per_page
        
        # Session state ƒë·ªÉ l∆∞u trang hi·ªán t·∫°i
        if 'current_page' not in st.session_state:
            st.session_state.current_page = 1
        
        # ƒêi·ªÅu h∆∞·ªõng trang
        col_nav1, col_nav2, col_nav3 = st.columns([1, 2, 1])
        
        with col_nav1:
            if st.button("‚èÆÔ∏è Trang ƒë·∫ßu", use_container_width=True):
                st.session_state.current_page = 1
                st.rerun()
            if st.button("‚óÄÔ∏è Trang tr∆∞·ªõc", use_container_width=True):
                if st.session_state.current_page > 1:
                    st.session_state.current_page -= 1
                    st.rerun()
        
        with col_nav2:
            current_page = st.session_state.current_page
            st.info(f"üìÑ Trang {current_page} / {total_pages} | D√≤ng {(current_page-1)*rows_per_page + 1} - {min(current_page*rows_per_page, total_rows)} / {total_rows}")
        
        with col_nav3:
            if st.button("‚ñ∂Ô∏è Trang sau", use_container_width=True):
                if st.session_state.current_page < total_pages:
                    st.session_state.current_page += 1
                    st.rerun()
            if st.button("‚è≠Ô∏è Trang cu·ªëi", use_container_width=True):
                st.session_state.current_page = total_pages
                st.rerun()
        
        # Hi·ªÉn th·ªã d·ªØ li·ªáu theo trang
        start_idx = (st.session_state.current_page - 1) * rows_per_page
        end_idx = start_idx + rows_per_page
        page_data = df.iloc[start_idx:end_idx]
        
        st.dataframe(page_data, use_container_width=True, height=400)
    else:
        # Hi·ªÉn th·ªã to√†n b·ªô d·ªØ li·ªáu
        st.dataframe(df, use_container_width=True, height=600)

# TAB 2: PH√ÇN T√çCH T·ªàNH
with tab2:
    st.header("üîç Ph√¢n t√≠ch theo t·ªânh v√† KPI")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Dropdown ch·ªçn t·ªânh
        provinces = sorted([p for p in df['CTKD7'].dropna().unique()])
        province = st.selectbox(
            "Ch·ªçn t·ªânh",
            provinces,
            help="Ch·ªçn t·ªânh c·∫ßn ph√¢n t√≠ch"
        )
        
        # T√¨m ki·∫øm t·ªânh
        search_province = st.text_input("üîç T√¨m ki·∫øm t·ªânh (nh·∫≠p m·ªôt ph·∫ßn t√™n)")
        if search_province:
            filtered_provinces = [p for p in provinces if search_province.lower() in str(p).lower()]
            if filtered_provinces:
                province = st.selectbox("T·ªânh t√¨m th·∫•y", filtered_provinces)
    
    with col2:
        # Dropdown ch·ªçn KPI (hi·ªÉn th·ªã t√™n th√¢n thi·ªán)
        def _norm(s: str) -> str:
            s = unicodedata.normalize('NFD', str(s))
            s = ''.join(ch for ch in s if unicodedata.category(ch) != 'Mn')
            s = s.upper().replace(' ', '').replace('-', '').replace('.', '').replace('_', '_')
            return s
        tokens = ['MTCL', 'CSSR', 'CDR', 'HOSR', 'ERAB', 'DATA', 'VN', 'QOS', 'SR', 'DR', 'COVERAGE', 'CHATLUONG', 'SUCO', 'SU_CO', 'SCL', 'SCNT1', 'SCRNT']
        kpi_cols_raw = [c for c in df.columns if any(t in _norm(c) for t in tokens)]
        # Map t√™n hi·ªÉn th·ªã th√¢n thi·ªán
        alias_display_map = {
            'ID4G_USR_DL_THP': '4G_USR_DL_THP',  # hi·ªÉn th·ªã ƒë·∫πp
        }
        # Th√™m alias hi·ªÉn th·ªã cho c√°c c·ªôt s·ª± c·ªë n·∫øu t√™n g·ªëc l√† ti·∫øng Vi·ªát c√≥ d·∫•u
        for c in df.columns:
            cn = _norm(c)
            if 'SUCOLON' == cn or cn == 'SCL':
                alias_display_map[c] = 'SuCoLon'
            elif 'SUCONGHIEMTRONG' == cn or cn == 'SCNT1':
                alias_display_map[c] = 'SuCoNghiemTrong'
            elif 'SUCORATNGHIEMTRONG' == cn or cn == 'SCRNT':
                alias_display_map[c] = 'SuCoRatNghiemTrong'
            elif 'COVERAGE4G' == cn or 'CHATLUONGVUNGPHU' == cn:
                alias_display_map[c] = 'ChatLuongVungPhu'
        kpi_display_options = [alias_display_map.get(c, c) for c in kpi_cols_raw]
        selected_kpi_display = st.selectbox(
            "Ch·ªçn KPI",
            kpi_display_options,
            help="Ch·ªçn KPI c·∫ßn ph√¢n t√≠ch"
        )
        # Map ng∆∞·ª£c v·ªÅ t√™n c·ªôt th·ª±c t·∫ø
        if selected_kpi_display == '4G_USR_DL_THP':
            if '4G_USR_DL_THP' in df.columns:
                kpi = '4G_USR_DL_THP'
            else:
                kpi = 'ID4G_USR_DL_THP'
        else:
            # T√¨m ng∆∞·ª£c theo alias n·∫øu l√† s·ª± c·ªë ho·∫∑c v√πng ph·ªß
            reverse_map = {v: k for k, v in alias_display_map.items()}
            if selected_kpi_display in reverse_map:
                kpi = reverse_map[selected_kpi_display]
            else:
                kpi = selected_kpi_display
        
        # T√¨m ki·∫øm KPI
        search_kpi = st.text_input("üîç T√¨m ki·∫øm KPI (nh·∫≠p m·ªôt ph·∫ßn t√™n)")
        if search_kpi:
            matched_kpi, candidates = fuzzy_match_kpi(search_kpi, df.columns)
            if matched_kpi:
                kpi = st.selectbox("KPI t√¨m th·∫•y", [matched_kpi] + candidates[:5])
    
    # L·ªçc ng√†y - T√≠nh nƒÉng lo·∫°i b·ªè ng√†y b·ªã l·ªói (gi·ªëng nh∆∞ tab "T·∫•t c·∫£ t·ªânh")
    st.subheader("üîß L·ªçc ng√†y")
    col_filter1, col_filter2 = st.columns(2)
    
    with col_filter1:
        # L·∫•y danh s√°ch ng√†y c√≥ d·ªØ li·ªáu (chu·∫©n h√≥a theo datetime ƒë·ªÉ s·∫Øp x·∫øp ƒë√∫ng)
        all_dates_dt = pd.to_datetime(df['Ngay7'], format='%d/%m/%Y', errors='coerce').dropna()
        all_dates_dt = all_dates_dt.sort_values().unique()
        all_dates = [d.strftime('%d/%m/%Y') for d in all_dates_dt]
        all_dates_str = all_dates
        
        # Multi-select ƒë·ªÉ ch·ªçn ng√†y c·∫ßn lo·∫°i b·ªè
        excluded_dates_province = st.multiselect(
            "‚ùå Ch·ªçn ng√†y c·∫ßn lo·∫°i b·ªè (ng√†y b·ªã l·ªói)",
            options=all_dates_str,
            help="Ch·ªçn c√°c ng√†y c√≥ d·ªØ li·ªáu l·ªói ƒë·ªÉ lo·∫°i b·ªè kh·ªèi bi·ªÉu ƒë·ªì",
            default=[],
            key="exclude_dates_province"
        )
    
    with col_filter2:
        # Ch·ªçn kho·∫£ng ng√†y ƒë·ªÉ hi·ªÉn th·ªã (gi·ªëng nh∆∞ tab "T·∫•t c·∫£ t·ªânh")
        if len(all_dates) > 0:
            # Convert dates for date_input
            try:
                date_min_prov = pd.to_datetime(all_dates[0], format='%d/%m/%Y', errors='coerce')
                date_max_prov = pd.to_datetime(all_dates[-1], format='%d/%m/%Y', errors='coerce')
                
                if pd.notna(date_min_prov) and pd.notna(date_max_prov):
                    date_range_province = st.date_input(
                        "üìÖ Ch·ªçn kho·∫£ng ng√†y hi·ªÉn th·ªã",
                        value=(date_min_prov.date(), date_max_prov.date()),
                        min_value=date_min_prov.date(),
                        max_value=date_max_prov.date(),
                        help="Ch·ªçn kho·∫£ng ng√†y mu·ªën xem trong bi·ªÉu ƒë·ªì",
                        key="date_range_province"
                    )
                else:
                    date_range_province = None
            except:
                date_range_province = None
        else:
            date_range_province = None
    
    # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì ngay khi ch·ªçn t·ªânh v√† KPI
    if province and kpi:
        province_data = df[df['CTKD7'] == province].copy()
        if len(province_data) > 0 and kpi in province_data.columns:
            kpi_data = province_data[['Ngay7', kpi]].copy()
            kpi_data = kpi_data[(kpi_data[kpi].notna()) & (kpi_data[kpi] != 0)]
            
            # Lo·∫°i b·ªè ng√†y ƒë∆∞·ª£c ch·ªçn
            if excluded_dates_province:
                kpi_data = kpi_data[~kpi_data['Ngay7'].isin(excluded_dates_province)]
            
            # L·ªçc theo kho·∫£ng ng√†y n·∫øu c√≥
            if date_range_province and len(date_range_province) == 2:
                kpi_data['Ngay7_dt'] = pd.to_datetime(kpi_data['Ngay7'], format='%d/%m/%Y', errors='coerce')
                start_date_prov = pd.Timestamp(date_range_province[0])
                end_date_prov = pd.Timestamp(date_range_province[1])
                kpi_data = kpi_data[
                    (kpi_data['Ngay7_dt'] >= start_date_prov) & 
                    (kpi_data['Ngay7_dt'] <= end_date_prov)
                ]
                kpi_data = kpi_data.drop('Ngay7_dt', axis=1)
            
            if len(kpi_data) > 0:
                st.subheader("üìà Bi·ªÉu ƒë·ªì xu h∆∞·ªõng")
                kpi_data['Ngay7'] = pd.to_datetime(kpi_data['Ngay7'], format='%d/%m/%Y', errors='coerce')
                kpi_data = kpi_data.sort_values('Ngay7')
                
                # Bi·ªÉu ƒë·ªì t∆∞∆°ng t√°c Streamlit (gi·ªØ ƒë·ªãnh d·∫°ng YYYY-MM-DD nh∆∞ tr∆∞·ªõc)
                kpi_data_display = kpi_data.copy()
                kpi_data_display['Ngay7'] = kpi_data_display['Ngay7'].dt.strftime('%Y-%m-%d')
                chart_data = kpi_data_display.set_index('Ngay7')[kpi].to_frame()
                chart_data.columns = [f'{kpi} - {province}']
                st.line_chart(chart_data)
                
                # Th√¥ng b√°o n·∫øu c√≥ ng√†y b·ªã lo·∫°i b·ªè
                if excluded_dates_province:
                    st.info(f"‚ö†Ô∏è ƒê√£ lo·∫°i b·ªè {len(excluded_dates_province)} ng√†y: {', '.join(excluded_dates_province[:5])}{'...' if len(excluded_dates_province) > 5 else ''}")
                
                # Th·ªëng k√™ nhanh
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Gi√° tr·ªã m·ªõi nh·∫•t", f"{kpi_data[kpi].iloc[-1]:.2f}")
                with col2:
                    st.metric("Trung b√¨nh", f"{kpi_data[kpi].mean():.2f}")
                with col3:
                    change_pct = ((kpi_data[kpi].iloc[-1] - kpi_data[kpi].iloc[0]) / kpi_data[kpi].iloc[0]) * 100
                    st.metric("Thay ƒë·ªïi t·ªïng", f"{change_pct:.2f}%")
    
    # N√∫t ph√¢n t√≠ch
    if st.button("üöÄ Ph√¢n t√≠ch chi ti·∫øt", type="primary", use_container_width=True):
        with st.spinner("ƒêang ph√¢n t√≠ch..."):
            try:
                # G·ªçi h√†m ph√¢n t√≠ch
                result = analyze_province_kpi(
                    province, 
                    kpi, 
                    file_path=file_path,
                    lookback_days=lookback_days,
                    decline_threshold=decline_threshold
                )
                
                if result:
                    detector_result, alerts, matched_province = result
                    
                    # Hi·ªÉn th·ªã k·∫øt qu·∫£
                    st.success(f"‚úÖ Ph√¢n t√≠ch ho√†n th√†nh cho {matched_province} - {kpi}")
                    
                    # Th·ªëng k√™
                    province_data = df[df['CTKD7'] == matched_province].copy()
                    kpi_data = province_data[['Ngay7', kpi]].copy()
                    kpi_data = kpi_data.sort_values('Ngay7')
                    kpi_data = kpi_data[(kpi_data[kpi].notna()) & (kpi_data[kpi] != 0)]
                    
                    # Lo·∫°i b·ªè ng√†y ƒë∆∞·ª£c ch·ªçn
                    if excluded_dates_province:
                        kpi_data = kpi_data[~kpi_data['Ngay7'].isin(excluded_dates_province)]
                    
                    # L·ªçc theo kho·∫£ng ng√†y n·∫øu c√≥
                    if date_range_province and len(date_range_province) == 2:
                        kpi_data['Ngay7_dt'] = pd.to_datetime(kpi_data['Ngay7'], format='%d/%m/%Y', errors='coerce')
                        start_date_prov = pd.Timestamp(date_range_province[0])
                        end_date_prov = pd.Timestamp(date_range_province[1])
                        kpi_data = kpi_data[
                            (kpi_data['Ngay7_dt'] >= start_date_prov) & 
                            (kpi_data['Ngay7_dt'] <= end_date_prov)
                        ]
                        kpi_data = kpi_data.drop('Ngay7_dt', axis=1)
                    
                    if len(kpi_data) > 0:
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("Min", f"{kpi_data[kpi].min():.2f}")
                        with col2:
                            st.metric("Max", f"{kpi_data[kpi].max():.2f}")
                        with col3:
                            st.metric("Trung b√¨nh", f"{kpi_data[kpi].mean():.2f}")
                        with col4:
                            st.metric("Gi√° tr·ªã m·ªõi nh·∫•t", f"{kpi_data[kpi].iloc[-1]:.2f}")
                    
                    # Hi·ªÉn th·ªã alerts n·∫øu c√≥
                    if alerts:
                        st.warning(f"‚ö†Ô∏è Ph√°t hi·ªán {len(alerts)} c·∫£nh b√°o suy gi·∫£m:")
                        for alert in alerts:
                            st.error(f"""
                            **T·ªânh**: {alert['province']}  
                            **KPI**: {alert['kpi']}  
                            **Ng√†y**: {alert['latest_date'].strftime('%d/%m/%Y')}  
                            **Suy gi·∫£m**: {alert['decline_pct']:.2f}%  
                            **M·ª©c ƒë·ªô**: {alert['severity']}
                            """)
                    else:
                        st.info("‚úÖ Kh√¥ng ph√°t hi·ªán suy gi·∫£m m·∫°nh")
                    
                    # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
                    st.subheader("üìà Bi·ªÉu ƒë·ªì xu h∆∞·ªõng KPI")
                    
                    if len(kpi_data) > 0:
                        # Chu·∫©n h√≥a ng√†y
                        kpi_data['Ngay7'] = pd.to_datetime(kpi_data['Ngay7'], format='%d/%m/%Y', errors='coerce')
                        kpi_data = kpi_data.sort_values('Ngay7')
                        
                        # T·∫°o bi·ªÉu ƒë·ªì
                        fig, ax = plt.subplots(figsize=(14, 6))
                        ax.plot(kpi_data['Ngay7'], kpi_data[kpi], marker='o', linewidth=2, markersize=4)
                        ax.set_title(f'{kpi} - {matched_province}', fontsize=14, fontweight='bold')
                        ax.set_xlabel('Ng√†y', fontsize=12)
                        ax.set_ylabel('', fontsize=12)  # B·ªè label tr·ª•c Y
                        ax.grid(True, alpha=0.3)
                        
                        # Hi·ªÉn th·ªã t·∫•t c·∫£ c√°c ng√†y tr√™n tr·ª•c x (b·∫•t k·ª≥ kho·∫£ng ng√†y n√†o)
                        ax.xaxis.set_major_locator(DayLocator(interval=1))  # Lu√¥n hi·ªÉn th·ªã t·∫•t c·∫£ c√°c ng√†y
                        ax.xaxis.set_major_formatter(DateFormatter('%d/%m/%Y'))
                        ax.tick_params(axis='x', rotation=45)
                        
                        # ƒê·∫£m b·∫£o tr·ª•c Y lu√¥n hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß s·ªë khi ph√≥ng to
                        ax.tick_params(axis='y', which='both', labelsize=10)
                        ax.yaxis.set_minor_locator(plt.NullLocator())  # T·∫Øt minor ticks
                        # Force hi·ªÉn th·ªã t·ªëi thi·ªÉu s·ªë tick tr√™n tr·ª•c Y
                        ax.yaxis.set_major_locator(MaxNLocator(nbins=10, integer=False))
                        # Format 2 ch·ªØ s·ªë th·∫≠p ph√¢n cho tr·ª•c Y
                        ax.yaxis.set_major_formatter(FuncFormatter(lambda y, pos: f"{y:.2f}"))
                        # TƒÉng margin b√™n tr√°i ƒë·ªÉ c√≥ ch·ªó hi·ªÉn th·ªã s·ªë
                        fig.subplots_adjust(left=0.10, right=0.95, top=0.93, bottom=0.15)
                        
                        # ƒêi·ªÅu ch·ªânh layout ƒë·ªÉ tr√°nh nh√£n b·ªã c·∫Øt
                        plt.setp(ax.xaxis.get_majorticklabels(), ha='right')
                        
                        # TƒÉng k√≠ch th∆∞·ªõc bi·ªÉu ƒë·ªì khi c√≥ nhi·ªÅu ng√†y ƒë·ªÉ hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß
                        num_days = len(kpi_data)
                        if num_days > 30:
                            fig.set_size_inches(18, 6)
                        elif num_days > 20:
                            fig.set_size_inches(16, 6)
                        else:
                            fig.set_size_inches(14, 6)
                        
                        # Highlight lookback days
                        if lookback_days and len(kpi_data) >= lookback_days:
                            latest_date = kpi_data['Ngay7'].iloc[-1]
                            lookback_date = latest_date - pd.Timedelta(days=lookback_days)
                            mask = kpi_data['Ngay7'] >= lookback_date
                            ax.plot(kpi_data[mask]['Ngay7'], kpi_data[mask][kpi], 
                                   marker='o', linewidth=3, markersize=6, 
                                   color='red', label=f'{lookback_days} ng√†y g·∫ßn nh·∫•t')
                            ax.legend()
                        
                        plt.tight_layout()
                        st.pyplot(fig)
                        plt.close(fig)
                        
                        # Th√™m bi·ªÉu ƒë·ªì t∆∞∆°ng t√°c b·∫±ng Streamlit (YYYY-MM-DD)
                        st.subheader("üìä Bi·ªÉu ƒë·ªì t∆∞∆°ng t√°c")
                        kpi_data_display = kpi_data.copy()
                        kpi_data_display['Ngay7'] = kpi_data_display['Ngay7'].dt.strftime('%Y-%m-%d')
                        st.line_chart(kpi_data_display.set_index('Ngay7')[kpi])
                    else:
                        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì")
                        
            except Exception as e:
                st.error(f"‚ùå L·ªói khi ph√¢n t√≠ch: {str(e)}")
                st.exception(e)

# TAB 3: T·∫§T C·∫¢ T·ªàNH
with tab3:
    st.header("üìà Ph√¢n t√≠ch t·∫•t c·∫£ t·ªânh")
    
    # Ch·ªçn KPI (hi·ªÉn th·ªã t√™n th√¢n thi·ªán) - t√≠nh ƒë·ªôc l·∫≠p ƒë·ªÉ kh√¥ng ph·ª• thu·ªôc bi·∫øn tr∆∞·ªõc ƒë√≥
    def _norm2(s: str) -> str:
        import unicodedata as _ud
        s = _ud.normalize('NFD', str(s))
        s = ''.join(ch for ch in s if _ud.category(ch) != 'Mn')
        return s.upper().replace(' ', '').replace('-', '').replace('.', '')
    # B·ªï sung c√°c m√£ c·ªôt s·ª± c·ªë d·∫°ng vi·∫øt t·∫Øt: SCL, SCNT1, SCRNT
    tokens_all = ['MTCL', 'CSSR', 'CDR', 'HOSR', 'ERAB', 'DATA', 'VN', 'QOS', 'SR', 'DR', 'COVERAGE', 'CHATLUONG', 'SUCO', 'SU_CO', 'SCL', 'SCNT1', 'SCRNT']
    kpi_cols_raw_all = [c for c in df.columns if any(t in _norm2(c) for t in tokens_all)]
    alias_display_map_all = {'ID4G_USR_DL_THP': '4G_USR_DL_THP'}
    # B·ªï sung alias cho s·ª± c·ªë v√† v√πng ph·ªß
    for c in kpi_cols_raw_all:
        cn = _norm2(c)
        if cn in ('SUCOLON', 'SCL'):
            alias_display_map_all[c] = 'SuCoLon'
        elif cn in ('SUCONGHIEMTRONG', 'SCNT1'):
            alias_display_map_all[c] = 'SuCoNghiemTrong'
        elif cn in ('SUCORATNGHIEMTRONG', 'SCRNT'):
            alias_display_map_all[c] = 'SuCoRatNghiemTrong'
        elif cn in ('COVERAGE4G', 'CHATLUONGVUNGPHU'):
            alias_display_map_all[c] = 'ChatLuongVungPhu'
    kpi_display_options_all = [alias_display_map_all.get(c, c) for c in kpi_cols_raw_all]
    selected_kpi_all_display = st.selectbox(
        "Ch·ªçn KPI ƒë·ªÉ ph√¢n t√≠ch cho t·∫•t c·∫£ t·ªânh",
        kpi_display_options_all
    )
    if selected_kpi_all_display == '4G_USR_DL_THP':
        if '4G_USR_DL_THP' in df.columns:
            kpi_all = '4G_USR_DL_THP'
        else:
            kpi_all = 'ID4G_USR_DL_THP'
    else:
        reverse_map_all = {v: k for k, v in alias_display_map_all.items()}
        if selected_kpi_all_display in reverse_map_all:
            kpi_all = reverse_map_all[selected_kpi_all_display]
        else:
            kpi_all = selected_kpi_all_display
    
    # L·ªçc ng√†y - T√≠nh nƒÉng lo·∫°i b·ªè ng√†y b·ªã l·ªói
    st.subheader("üîß L·ªçc ng√†y")
    col_filter1, col_filter2 = st.columns(2)
    
    with col_filter1:
        # L·∫•y danh s√°ch ng√†y c√≥ d·ªØ li·ªáu (chu·∫©n h√≥a theo datetime ƒë·ªÉ s·∫Øp x·∫øp ƒë√∫ng)
        all_dates_dt = pd.to_datetime(df['Ngay7'], format='%d/%m/%Y', errors='coerce').dropna()
        all_dates_dt = all_dates_dt.sort_values().unique()
        # Format ng√†y theo D/M/Y (b·ªè gi·ªù)
        all_dates_str = [d.strftime('%d/%m/%Y') for d in all_dates_dt]
        
        # Multi-select ƒë·ªÉ ch·ªçn ng√†y c·∫ßn lo·∫°i b·ªè
        excluded_dates = st.multiselect(
            "‚ùå Ch·ªçn ng√†y c·∫ßn lo·∫°i b·ªè (ng√†y b·ªã l·ªói)",
            options=all_dates_str,
            help="Ch·ªçn c√°c ng√†y c√≥ d·ªØ li·ªáu l·ªói ƒë·ªÉ lo·∫°i b·ªè kh·ªèi bi·ªÉu ƒë·ªì",
            default=[]
        )
    
    with col_filter2:
        # Ch·ªçn kho·∫£ng ng√†y ƒë·ªÉ hi·ªÉn th·ªã (d·ª±a tr√™n min/max datetime th·ª±c t·∫ø)
        if len(all_dates_dt) > 0:
            try:
                date_min = pd.to_datetime(all_dates_dt.min(), errors='coerce')
                date_max = pd.to_datetime(all_dates_dt.max(), errors='coerce')
                
                if pd.notna(date_min) and pd.notna(date_max):
                    date_range = st.date_input(
                        "üìÖ Ch·ªçn kho·∫£ng ng√†y hi·ªÉn th·ªã",
                        value=(date_min.date(), date_max.date()),
                        min_value=date_min.date(),
                        max_value=date_max.date(),
                        help="Ch·ªçn kho·∫£ng ng√†y mu·ªën xem trong bi·ªÉu ƒë·ªì"
                    )
                else:
                    date_range = None
            except:
                date_range = None
        else:
            date_range = None
    
    # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì t·∫•t c·∫£ t·ªânh ngay khi ch·ªçn KPI
    if kpi_all:
        st.subheader("üìä Bi·ªÉu ƒë·ªì so s√°nh t·∫•t c·∫£ t·ªânh")
        
        # L·∫•y d·ªØ li·ªáu cho t·∫•t c·∫£ t·ªânh
        all_provinces_data = []
        provinces_list = sorted([p for p in df['CTKD7'].dropna().unique()])
        
        for province_name in provinces_list:
            province_data = df[df['CTKD7'] == province_name].copy()
            if len(province_data) > 0 and kpi_all in province_data.columns:
                kpi_data = province_data[['Ngay7', kpi_all]].copy()
                kpi_data = kpi_data[(kpi_data[kpi_all].notna()) & (kpi_data[kpi_all] != 0)]
                
                # Lo·∫°i b·ªè ng√†y ƒë∆∞·ª£c ch·ªçn
                if excluded_dates:
                    kpi_data = kpi_data[~kpi_data['Ngay7'].isin(excluded_dates)]
                
                # L·ªçc theo kho·∫£ng ng√†y n·∫øu c√≥
                if date_range and len(date_range) == 2:
                    kpi_data['Ngay7_dt'] = pd.to_datetime(kpi_data['Ngay7'], format='%d/%m/%Y', errors='coerce')
                    start_date = pd.Timestamp(date_range[0])
                    end_date = pd.Timestamp(date_range[1])
                    kpi_data = kpi_data[
                        (kpi_data['Ngay7_dt'] >= start_date) & 
                        (kpi_data['Ngay7_dt'] <= end_date)
                    ]
                    kpi_data = kpi_data.drop('Ngay7_dt', axis=1)
                
                if len(kpi_data) > 0:
                    kpi_data['Ngay7'] = pd.to_datetime(kpi_data['Ngay7'], format='%d/%m/%Y', errors='coerce')
                    kpi_data = kpi_data.sort_values('Ngay7')
                    kpi_data['T·ªânh'] = province_name
                    all_provinces_data.append(kpi_data[['Ngay7', kpi_all, 'T·ªânh']])
        
        if all_provinces_data:
            # T·∫°o DataFrame t·ªïng h·ª£p
            combined_df = pd.concat(all_provinces_data, ignore_index=True)  # gi·ªØ datetime
            
            # Pivot ƒë·ªÉ c√≥ m·ªói t·ªânh l√† m·ªôt c·ªôt v√† v·∫Ω b·∫±ng Streamlit
            pivot_df = combined_df.pivot_table(
                index='Ngay7', 
                columns='T·ªânh', 
                values=kpi_all,
                aggfunc='first'
            )
            if len(pivot_df) > 0:
                # ƒê·ªãnh d·∫°ng index v·ªÅ chu·ªói YYYY-MM-DD nh∆∞ tr∆∞·ªõc
                pivot_df = pivot_df.copy()
                pivot_df.index = pivot_df.index.strftime('%Y-%m-%d')
                st.line_chart(pivot_df)
                
                # Th√¥ng b√°o n·∫øu c√≥ ng√†y b·ªã lo·∫°i b·ªè
                if excluded_dates:
                    st.info(f"‚ö†Ô∏è ƒê√£ lo·∫°i b·ªè {len(excluded_dates)} ng√†y: {', '.join(excluded_dates[:5])}{'...' if len(excluded_dates) > 5 else ''}")
            else:
                st.warning("‚ö†Ô∏è Kh√¥ng c√≤n d·ªØ li·ªáu sau khi l·ªçc. Vui l√≤ng ƒëi·ªÅu ch·ªânh b·ªô l·ªçc.")
            
            # Th·ªëng k√™ nhanh
            st.subheader("üìä Th·ªëng k√™ nhanh")
            stats_cols = st.columns(min(4, len(provinces_list)))
            
            for idx, province_name in enumerate(provinces_list[:4]):
                with stats_cols[idx]:
                    province_data = df[df['CTKD7'] == province_name].copy()
                    if len(province_data) > 0 and kpi_all in province_data.columns:
                        kpi_data = province_data[['Ngay7', kpi_all]].copy()
                        kpi_data = kpi_data[(kpi_data[kpi_all].notna()) & (kpi_data[kpi_all] != 0)]
                        if len(kpi_data) > 0:
                            latest_value = kpi_data[kpi_all].iloc[-1]
                            st.metric(province_name[:20], f"{latest_value:.2f}")
    
    if st.button("üîç Ph√¢n t√≠ch chi ti·∫øt t·∫•t c·∫£ t·ªânh", type="primary"):
        with st.spinner("ƒêang ph√¢n t√≠ch t·∫•t c·∫£ t·ªânh..."):
            try:
                alerts = detector.detect_declines(kpi_all, lookback_days=lookback_days)
                
                if alerts:
                    st.warning(f"‚ö†Ô∏è Ph√°t hi·ªán {len(alerts)} t·ªânh c√≥ suy gi·∫£m {kpi_all}")
                    
                    # T·∫°o DataFrame ƒë·ªÉ hi·ªÉn th·ªã
                    alerts_df = pd.DataFrame(alerts)
                    alerts_df = alerts_df[['province', 'kpi', 'latest_date', 'latest_value', 
                                         'compare_value', 'decline_pct', 'severity']]
                    alerts_df['latest_date'] = alerts_df['latest_date'].dt.strftime('%d/%m/%Y')
                    alerts_df.columns = ['T·ªânh', 'KPI', 'Ng√†y', 'Gi√° tr·ªã hi·ªán t·∫°i', 
                                        'Gi√° tr·ªã tr∆∞·ªõc', 'Suy gi·∫£m (%)', 'M·ª©c ƒë·ªô']
                    
                    st.dataframe(alerts_df, use_container_width=True)
                    
                    # V·∫Ω bi·ªÉu ƒë·ªì cho c√°c t·ªânh c√≥ v·∫•n ƒë·ªÅ
                    st.subheader("üìà Bi·ªÉu ƒë·ªì c√°c t·ªânh c√≥ suy gi·∫£m")
                    
                    if len(alerts) > 0:
                        # L·∫•y danh s√°ch t·ªânh c√≥ v·∫•n ƒë·ªÅ
                        provinces_with_issues = [a['province'] for a in alerts]
                        
                        # T·∫°o bi·ªÉu ƒë·ªì matplotlib
                        fig, ax = plt.subplots(figsize=(14, 8))
                        
                        for province_name in provinces_with_issues:
                            province_data = df[df['CTKD7'] == province_name].copy()
                            if len(province_data) > 0 and kpi_all in province_data.columns:
                                kpi_data = province_data[['Ngay7', kpi_all]].copy()
                                kpi_data = kpi_data[(kpi_data[kpi_all].notna()) & (kpi_data[kpi_all] != 0)]
                                
                                # Lo·∫°i b·ªè ng√†y ƒë∆∞·ª£c ch·ªçn
                                if excluded_dates:
                                    kpi_data = kpi_data[~kpi_data['Ngay7'].isin(excluded_dates)]
                                
                                # L·ªçc theo kho·∫£ng ng√†y n·∫øu c√≥
                                if date_range and len(date_range) == 2:
                                    kpi_data['Ngay7_dt'] = pd.to_datetime(kpi_data['Ngay7'], format='%d/%m/%Y', errors='coerce')
                                    start_date = pd.Timestamp(date_range[0])
                                    end_date = pd.Timestamp(date_range[1])
                                    kpi_data = kpi_data[
                                        (kpi_data['Ngay7_dt'] >= start_date) & 
                                        (kpi_data['Ngay7_dt'] <= end_date)
                                    ]
                                    kpi_data = kpi_data.drop('Ngay7_dt', axis=1)
                                
                                if len(kpi_data) > 0:
                                    kpi_data['Ngay7'] = pd.to_datetime(kpi_data['Ngay7'], format='%d/%m/%Y', errors='coerce')
                                    kpi_data = kpi_data.sort_values('Ngay7')
                                    
                                    # T√¨m m·ª©c ƒë·ªô nghi√™m tr·ªçng
                                    alert = next((a for a in alerts if a['province'] == province_name), None)
                                    if alert:
                                        severity = alert['severity']
                                        if severity == 'C·ª±c k·ª≥ nghi√™m tr·ªçng':
                                            color = 'red'
                                            linewidth = 3
                                        elif severity == 'Nghi√™m tr·ªçng':
                                            color = 'orange'
                                            linewidth = 2.5
                                        elif severity == 'C·∫£nh b√°o':
                                            color = 'yellow'
                                            linewidth = 2
                                        else:
                                            color = 'blue'
                                            linewidth = 1.5
                                    else:
                                        color = 'gray'
                                        linewidth = 1.5
                                    
                                    ax.plot(kpi_data['Ngay7'], kpi_data[kpi_all], 
                                           marker='o', linewidth=linewidth, markersize=3,
                                           label=f"{province_name} ({severity if alert else 'OK'})",
                                           color=color, alpha=0.7)
                        
                        ax.set_title(f'{kpi_all} - C√°c t·ªânh c√≥ suy gi·∫£m', fontsize=16, fontweight='bold')
                        ax.set_xlabel('Ng√†y', fontsize=12)
                        ax.set_ylabel('', fontsize=12)  # B·ªè label tr·ª•c Y
                        ax.grid(True, alpha=0.3)
                        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
                        
                        # Hi·ªÉn th·ªã t·∫•t c·∫£ c√°c ng√†y tr√™n tr·ª•c x (b·∫•t k·ª≥ kho·∫£ng ng√†y n√†o)
                        ax.xaxis.set_major_locator(DayLocator(interval=1))  # Lu√¥n hi·ªÉn th·ªã t·∫•t c·∫£ c√°c ng√†y
                        ax.xaxis.set_major_formatter(DateFormatter('%d/%m/%Y'))
                        ax.tick_params(axis='x', rotation=45)
                        plt.setp(ax.xaxis.get_majorticklabels(), ha='right')
                        
                        # ƒê·∫£m b·∫£o tr·ª•c Y lu√¥n hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß s·ªë khi ph√≥ng to
                        ax.tick_params(axis='y', which='both', labelsize=10)
                        ax.yaxis.set_minor_locator(plt.NullLocator())  # T·∫Øt minor ticks
                        # Force hi·ªÉn th·ªã t·ªëi thi·ªÉu s·ªë tick tr√™n tr·ª•c Y
                        ax.yaxis.set_major_locator(MaxNLocator(nbins=10, integer=False))
                        # Format 2 ch·ªØ s·ªë th·∫≠p ph√¢n cho tr·ª•c Y
                        ax.yaxis.set_major_formatter(FuncFormatter(lambda y, pos: f"{y:.2f}"))
                        # TƒÉng margin b√™n tr√°i ƒë·ªÉ c√≥ ch·ªó hi·ªÉn th·ªã s·ªë (ƒë·∫∑c bi·ªát khi c√≥ legend b√™n ph·∫£i)
                        fig.subplots_adjust(left=0.10, right=0.85, top=0.93, bottom=0.15)
                        
                        # T√≠nh s·ªë ng√†y v√† tƒÉng k√≠ch th∆∞·ªõc bi·ªÉu ƒë·ªì khi c√≥ nhi·ªÅu ng√†y
                        all_dates_in_chart = set()
                        for province_name in provinces_with_issues:
                            province_data_temp = df[df['CTKD7'] == province_name].copy()
                            if len(province_data_temp) > 0 and kpi_all in province_data_temp.columns:
                                kpi_data_temp = province_data_temp[['Ngay7', kpi_all]].copy()
                                kpi_data_temp = kpi_data_temp[(kpi_data_temp[kpi_all].notna()) & (kpi_data_temp[kpi_all] != 0)]
                                if excluded_dates:
                                    kpi_data_temp = kpi_data_temp[~kpi_data_temp['Ngay7'].isin(excluded_dates)]
                                all_dates_in_chart.update(kpi_data_temp['Ngay7'].unique())
                        
                        num_days = len(all_dates_in_chart)
                        if num_days > 30:
                            fig.set_size_inches(20, 8)
                        elif num_days > 20:
                            fig.set_size_inches(18, 8)
                        else:
                            fig.set_size_inches(16, 8)
                        
                        plt.tight_layout()
                        st.pyplot(fig)
                        plt.close(fig)
                    
                    # Download CSV
                    csv = alerts_df.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="üì• Download b√°o c√°o CSV",
                        data=csv,
                        file_name=f"alerts_{kpi_all}_{datetime.now().strftime('%Y%m%d')}.csv",
                        mime="text/csv"
                    )
                else:
                    st.success("‚úÖ Kh√¥ng ph√°t hi·ªán suy gi·∫£m n√†o cho t·∫•t c·∫£ t·ªânh")
                    
                    # V·∫´n hi·ªÉn th·ªã bi·ªÉu ƒë·ªì t·∫•t c·∫£ t·ªânh (ƒë√£ l·ªçc)
                    st.subheader("üìà Bi·ªÉu ƒë·ªì t·∫•t c·∫£ t·ªânh")
                    if all_provinces_data:
                        # Rebuild v·ªõi filter n·∫øu c·∫ßn
                        filtered_all_provinces_data = []
                        for province_name in provinces_list:
                            province_data = df[df['CTKD7'] == province_name].copy()
                            if len(province_data) > 0 and kpi_all in province_data.columns:
                                kpi_data = province_data[['Ngay7', kpi_all]].copy()
                                kpi_data = kpi_data[(kpi_data[kpi_all].notna()) & (kpi_data[kpi_all] != 0)]
                                
                                # Lo·∫°i b·ªè ng√†y ƒë∆∞·ª£c ch·ªçn
                                if excluded_dates:
                                    kpi_data = kpi_data[~kpi_data['Ngay7'].isin(excluded_dates)]
                                
                                # L·ªçc theo kho·∫£ng ng√†y n·∫øu c√≥
                                if date_range and len(date_range) == 2:
                                    kpi_data['Ngay7_dt'] = pd.to_datetime(kpi_data['Ngay7'], format='%d/%m/%Y', errors='coerce')
                                    start_date = pd.Timestamp(date_range[0])
                                    end_date = pd.Timestamp(date_range[1])
                                    kpi_data = kpi_data[
                                        (kpi_data['Ngay7_dt'] >= start_date) & 
                                        (kpi_data['Ngay7_dt'] <= end_date)
                                    ]
                                    kpi_data = kpi_data.drop('Ngay7_dt', axis=1)
                                
                                if len(kpi_data) > 0:
                                    kpi_data['Ngay7'] = pd.to_datetime(kpi_data['Ngay7'], format='%d/%m/%Y', errors='coerce')
                                    kpi_data = kpi_data.sort_values('Ngay7')
                                    kpi_data['T·ªânh'] = province_name
                                    filtered_all_provinces_data.append(kpi_data[['Ngay7', kpi_all, 'T·ªânh']])
                        
                        if filtered_all_provinces_data:
                            combined_df = pd.concat(filtered_all_provinces_data, ignore_index=True)  # gi·ªØ datetime
                            pivot_df = combined_df.pivot_table(index='Ngay7', columns='T·ªânh', values=kpi_all, aggfunc='first')
                            pivot_df = pivot_df.copy()
                            pivot_df.index = pivot_df.index.strftime('%Y-%m-%d')
                            st.line_chart(pivot_df)
                    
            except Exception as e:
                st.error(f"‚ùå L·ªói: {str(e)}")
                st.exception(e)

# TAB 4: ALERTS
with tab4:
    st.header("üö® H·ªá th·ªëng c·∫£nh b√°o")
    
    st.info("""
    **T√≠nh nƒÉng n√†y s·∫Ω hi·ªÉn th·ªã t·∫•t c·∫£ c·∫£nh b√°o suy gi·∫£m KPI.**
    
    - Qu√©t t·∫•t c·∫£ KPI quan tr·ªçng
    - Ph√°t hi·ªán suy gi·∫£m theo ng∆∞·ª°ng ƒë√£ c·∫•u h√¨nh
    - Hi·ªÉn th·ªã danh s√°ch c·∫£nh b√°o chi ti·∫øt
    """)
    
    critical_kpis = st.multiselect(
        "Ch·ªçn KPI quan tr·ªçng c·∫ßn gi√°m s√°t",
        kpi_cols,
        default=['MTCL_2024', 'CSSR', 'CDR', 'HOSR_4G_2024'] if all(k in kpi_cols for k in ['MTCL_2024', 'CSSR', 'CDR', 'HOSR_4G_2024']) else kpi_cols[:4]
    )
    
    if st.button("üîç Qu√©t c·∫£nh b√°o", type="primary"):
        with st.spinner("ƒêang qu√©t t·∫•t c·∫£ KPI..."):
            all_alerts = []
            
            for kpi in critical_kpis:
                try:
                    alerts = detector.detect_declines(kpi, lookback_days=lookback_days)
                    all_alerts.extend(alerts)
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è L·ªói khi ph√¢n t√≠ch {kpi}: {str(e)}")
            
            if all_alerts:
                st.error(f"üö® Ph√°t hi·ªán {len(all_alerts)} c·∫£nh b√°o!")
                
                # Nh√≥m theo m·ª©c ƒë·ªô
                severity_counts = {}
                for alert in all_alerts:
                    sev = alert['severity']
                    severity_counts[sev] = severity_counts.get(sev, 0) + 1
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("C·ª±c k·ª≥ nghi√™m tr·ªçng", severity_counts.get('C·ª±c k·ª≥ nghi√™m tr·ªçng', 0))
                with col2:
                    st.metric("Nghi√™m tr·ªçng", severity_counts.get('Nghi√™m tr·ªçng', 0))
                with col3:
                    st.metric("C·∫£nh b√°o", severity_counts.get('C·∫£nh b√°o', 0))
                with col4:
                    st.metric("Nh·∫π", severity_counts.get('Nh·∫π', 0))
                
                # Hi·ªÉn th·ªã chi ti·∫øt
                alerts_df = pd.DataFrame(all_alerts)
                alerts_df = alerts_df.sort_values('decline_pct', ascending=False)
                st.dataframe(alerts_df, use_container_width=True)
            else:
                st.success("‚úÖ Kh√¥ng c√≥ c·∫£nh b√°o n√†o!")

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    <p>üìä H·ªá th·ªëng Gi√°m s√°t KPI | Ch·∫°y tr√™n laptop local</p>
    <p>Phi√™n b·∫£n 1.0 | S·ª≠ d·ª•ng Streamlit</p>
</div>
""", unsafe_allow_html=True)

